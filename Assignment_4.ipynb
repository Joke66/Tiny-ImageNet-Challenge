{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohebAbai/Tiny-ImageNet-Challenge/blob/master/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Tyav-Kv4Cluk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing libraries and Downloading Dataset"
      ]
    },
    {
      "metadata": {
        "id": "aMf7Mem__-f8",
        "colab_type": "code",
        "outputId": "d9ed3350-9fde-481a-b1c2-8789a0852d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JNaPivQDFCVu",
        "colab_type": "code",
        "outputId": "4817e63f-6576-4221-e379-38e2e923b8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "## Download the dataset and unzip it \n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-14 22:31:46--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  66.7MB/s    in 4.8s    \n",
            "\n",
            "2019-04-14 22:31:51 (49.4 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "anb0832EAX1P",
        "colab_type": "code",
        "outputId": "1eb5749b-3b2f-4adc-feb2-31c8bc909b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  tiny-imagenet-200\ttiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQaK0yk7Aa5q",
        "colab_type": "code",
        "outputId": "1104a0f0-e34b-479b-c06e-f85fdcf78e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OE5XWyuzaj7X",
        "colab_type": "code",
        "outputId": "949ac5b2-d923-4f5a-a059-ede636050558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-p9bsdlvh\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.16.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.9)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-kyhxk74g/wheels/eb/42/ea/ef324c6958836b1a3d4c0659214b0bae1c0a9bf151254dc93f\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g7LJSXVKAgPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SeparableConv2D\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras_contrib.callbacks import CyclicLR\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# random seed\n",
        "np.random.seed(seed=101)\n",
        "ia.seed(101)\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "# input image dimensions\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "channels = 3\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 200\n",
        "epochs = 24\n",
        "num_train = 100000\n",
        "num_validation = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uk0y7CZXAqvq",
        "colab_type": "code",
        "outputId": "95b7130c-4d06-46b2-d7e5-f50e65f711ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, \n",
        "                       names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "val_data.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_0.JPEG</td>\n",
              "      <td>n03444034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_1.JPEG</td>\n",
              "      <td>n04067472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_2.JPEG</td>\n",
              "      <td>n04070727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         File      Class\n",
              "0  val_0.JPEG  n03444034\n",
              "1  val_1.JPEG  n04067472\n",
              "2  val_2.JPEG  n04070727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "IfwTLY9ZCt6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "DrMP7ZvMAt0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining Customized Imagedatagenerator using imgaug library\n",
        "def CustomImageDataGen(input_img):\n",
        "  # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
        "  # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n",
        "  # image.\n",
        "  sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "  \n",
        "  seq = iaa.Sequential([\n",
        "      iaa.Fliplr(0.5), # horizontal flips\n",
        "      iaa.Flipud(0.2), # vertical flips\n",
        "      \n",
        "      # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "      # But we only blur about 50% of all images.\n",
        "      sometimes(iaa.GaussianBlur(sigma=(0, 2.0))),\n",
        "      \n",
        "      # crop images by -10% to 20% of their height/width\n",
        "      sometimes(iaa.CropAndPad(\n",
        "          percent=(-0.1, 0.2),\n",
        "          pad_mode=ia.ALL,\n",
        "          pad_cval=(0, 255)\n",
        "        )),\n",
        "      \n",
        "      # Apply affine transformations to some of the images\n",
        "      # - scale to 80-120% of image height/width (each axis independently)\n",
        "      # - translate by -20 to +20 relative to height/width (per axis)\n",
        "      # - rotate by -45 to +45 degrees\n",
        "      # - shear by -16 to +16 degrees\n",
        "      # - order: use nearest neighbour or bilinear interpolation (fast)\n",
        "      # - mode: use any available mode to fill newly created pixels\n",
        "      #         see API or scikit-image for which modes are available\n",
        "      # - cval: if the mode is constant, then use a random brightness\n",
        "      #         for the newly created pixels (e.g. sometimes black,\n",
        "      #         sometimes white)\n",
        "      sometimes(iaa.Affine(\n",
        "          scale={\"x\": (0.8, 1.5), \"y\": (0.8, 1.5)},\n",
        "          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "          rotate=(-45, 45),\n",
        "          shear=(-16, 16),\n",
        "          order=[0, 1],\n",
        "          cval=(0, 255),\n",
        "          mode=ia.ALL\n",
        "      )),\n",
        "      \n",
        "      #drop 2-5% percent of the original size, leading to large dropped\n",
        "      # rectangles.\n",
        "      sometimes(iaa.CoarseDropout(\n",
        "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
        "                        per_channel=0.2\n",
        "                    )),\n",
        "                \n",
        "      # Make some images brighter and some darker.\n",
        "      # In 20% of all cases, we sample the multiplier once per channel,\n",
        "      # which can end up changing the color of the images.\n",
        "      sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.2)),\n",
        "      \n",
        "      #Improve or worsen the contrast of images.\n",
        "      #Comment it out after third model run (extreme saturation)\n",
        "      sometimes(iaa.ContrastNormalization((0.75, 1.5), per_channel=0.5)), \n",
        "     ],\n",
        "     # do all of the above augmentations in random order\n",
        "     random_order = True) # apply augmenters in random order\n",
        "  \n",
        "  output_img = seq.augment_image(input_img)\n",
        "  return output_img\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255., preprocessing_function = CustomImageDataGen)\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QC4UyaJYAxxx",
        "colab_type": "code",
        "outputId": "98c2d91d-8da6-4cba-9e69-8f17697aa681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', \n",
        "                                                    target_size=(img_width, img_height), \n",
        "                                                    batch_size=batch_size, \n",
        "                                                    class_mode='categorical', \n",
        "                                                    shuffle=True, seed=101)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GDaw-gK8Az-l",
        "colab_type": "code",
        "outputId": "2b135115-47dd-4c1c-d260-2f98411200de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', \n",
        "                                                         x_col='File', y_col='Class', \n",
        "                                                         target_size=(img_width, img_height),\n",
        "                                                         class_mode='categorical', \n",
        "                                                         batch_size=batch_size, \n",
        "                                                         shuffle=False, seed=101)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2cfpTiutDDBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Building and Compilation"
      ]
    },
    {
      "metadata": {
        "id": "8c2YkRpjDFlQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Below is the custom Resnet Model, where architecture is inspired from Wide-Resnet and Resnet-18 keras models. As required for the project followings have not been used :\n",
        "1. 1x1 for an increasing number of channels\n",
        "2. dropout\n",
        "3. fully connected layers\n",
        "4. test dataset for training\n",
        "5. pre-trained model/weights\n",
        "6. someone else's code "
      ]
    },
    {
      "metadata": {
        "id": "WyewaBesA8RA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Note : For running the new model after 8 hours, don't run beyond this, as the saved model contains model architecture, weights and optimizer."
      ]
    },
    {
      "metadata": {
        "id": "DJ4fm3yibgcS",
        "colab_type": "code",
        "outputId": "36dc985d-ad3f-4ed0-f46c-93044c9d158d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Model building\n",
        "input = Input(shape=(img_height, img_width, channels))\n",
        "\n",
        "# Block 1\n",
        "layer0 = Conv2D(32, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(input)\n",
        "layer0 = BatchNormalization()(layer0)\n",
        "layer0 = Activation('relu')(layer0)\n",
        "\n",
        "skip_connection_1 = layer0\n",
        "\n",
        "# Block 2\n",
        "\n",
        "layer1 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer0)\n",
        "layer1 = BatchNormalization()(layer1)\n",
        "layer1 = Activation('relu')(layer1)\n",
        "\n",
        "layer2 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer1)\n",
        "layer2 = BatchNormalization()(layer2)\n",
        "layer2 = Activation('relu')(layer2)\n",
        "\n",
        "layer3 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer2)\n",
        "layer3 = BatchNormalization()(layer3)\n",
        "layer3 = Activation('relu')(layer3)\n",
        "\n",
        "layer4 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer3)\n",
        "layer4 = BatchNormalization()(layer4)\n",
        "layer4 = Activation('relu')(layer4)\n",
        "\n",
        "layer5 = concatenate([skip_connection_1, layer4])\n",
        "layer5 = BatchNormalization()(layer5)\n",
        "layer5 = Activation('relu')(layer5)\n",
        "layer5 = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
        "\n",
        "skip_connection_2 = layer5\n",
        "\n",
        "# Block 3\n",
        "\n",
        "layer6 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer5)\n",
        "layer6 = BatchNormalization()(layer6)\n",
        "layer6 = Activation('relu')(layer6)\n",
        "\n",
        "layer7 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer6)\n",
        "layer7 = BatchNormalization()(layer7)\n",
        "layer7 = Activation('relu')(layer7)\n",
        "\n",
        "layer8 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer7)\n",
        "layer8 = BatchNormalization()(layer8)\n",
        "layer8 = Activation('relu')(layer8)\n",
        "\n",
        "layer9 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer8)\n",
        "layer9 = BatchNormalization()(layer9)\n",
        "layer9 = Activation('relu')(layer9)\n",
        "\n",
        "layer10 = concatenate([skip_connection_2, layer9])\n",
        "layer10 = BatchNormalization()(layer10)\n",
        "layer10 = Activation('relu')(layer10)\n",
        "layer10 = MaxPooling2D(pool_size=(2, 2))(layer10)\n",
        "\n",
        "skip_connection_3 = layer10\n",
        "\n",
        "\n",
        "# Block 4\n",
        "\n",
        "layer11 = Conv2D(512, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer10)\n",
        "layer11 = BatchNormalization()(layer11)\n",
        "layer11 = Activation('relu')(layer11)\n",
        "\n",
        "layer12 = Conv2D(512, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer11)\n",
        "layer12 = BatchNormalization()(layer12)\n",
        "layer12 = Activation('relu')(layer12)\n",
        "\n",
        "layer13 = Conv2D(512, (3,3), padding='same',kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer12)\n",
        "layer13 = BatchNormalization()(layer13)\n",
        "layer13 = Activation('relu')(layer13)\n",
        "\n",
        "layer14 = Conv2D(512, (3,3), padding='same',kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer13)\n",
        "layer14 = BatchNormalization()(layer14)\n",
        "layer14 = Activation('relu')(layer14)\n",
        "\n",
        "layer15 = concatenate([skip_connection_3, layer14])\n",
        "layer15 = BatchNormalization()(layer15)\n",
        "layer15 = Activation('relu')(layer15)\n",
        "layer15 = MaxPooling2D(pool_size=(2, 2))(layer15)\n",
        "\n",
        "\n",
        "#Layer 16\n",
        "layer16 = Conv2D(num_classes, (1,1), padding='same',kernel_initializer=\"VarianceScaling\",kernel_regularizer=l2(2e-4))(layer15)\n",
        "layer16 = GlobalAveragePooling2D()(layer16)\n",
        "\n",
        "#Output Layer\n",
        "output = Activation('softmax')(layer16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3og9TJvCblde",
        "colab_type": "code",
        "outputId": "cc7490b1-29d4-4a21-ff1e-1bc276f12f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2101
        }
      },
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 128)  36992       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 128)  147584      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 160)  0           activation_1[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 160)  640         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 160)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 160)  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 256)  368896      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 416)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 416)  1664        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 416)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 416)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1917440     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 512)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 512)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 928)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 928)  3712        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 928)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 928)    0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 200)    185800      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 11,822,920\n",
            "Trainable params: 11,812,680\n",
            "Non-trainable params: 10,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kjvjtYk6bo6h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= RMSprop(lr= 0.0001, epsilon=1e-08),\n",
        "              #optimizer= Adam(lr= 0.0001, epsilon=1e-08),\n",
        "              #optimizer = SGD(momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "leAtQomIbrwq",
        "colab_type": "code",
        "outputId": "90a51ea1-2190-4938-e08d-c9f2c3f70f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1774
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "clr = CyclicLR(base_lr=0.0001, max_lr=0.0006, step_size=4686., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer = ModelCheckpoint(filepath=\"./drive/My Drive/Colab Notebooks/model1.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "\n",
        "# Fit the Model\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch= num_train // batch_size,\n",
        "                    validation_steps= num_validation // batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose=1, callbacks=[clr, checkpointer]\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/24\n",
            "781/781 [==============================] - 1278s 2s/step - loss: 5.4892 - acc: 0.0531 - val_loss: 5.1116 - val_acc: 0.0896\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.08964, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 2/24\n",
            "781/781 [==============================] - 1264s 2s/step - loss: 4.8541 - acc: 0.1075 - val_loss: 4.6112 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.08964 to 0.12774, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 3/24\n",
            "781/781 [==============================] - 1261s 2s/step - loss: 4.5329 - acc: 0.1398 - val_loss: 4.2920 - val_acc: 0.1792\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.12774 to 0.17919, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 4/24\n",
            "781/781 [==============================] - 1260s 2s/step - loss: 4.3436 - acc: 0.1672 - val_loss: 4.4600 - val_acc: 0.1747\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.17919\n",
            "Epoch 5/24\n",
            "781/781 [==============================] - 1261s 2s/step - loss: 4.2540 - acc: 0.1897 - val_loss: 4.5503 - val_acc: 0.1690\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.17919\n",
            "Epoch 6/24\n",
            "781/781 [==============================] - 1262s 2s/step - loss: 4.2554 - acc: 0.2038 - val_loss: 4.2981 - val_acc: 0.1975\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.17919 to 0.19753, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 7/24\n",
            "781/781 [==============================] - 1261s 2s/step - loss: 4.2213 - acc: 0.2280 - val_loss: 4.4195 - val_acc: 0.2100\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.19753 to 0.20999, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 8/24\n",
            "781/781 [==============================] - 1260s 2s/step - loss: 4.1162 - acc: 0.2603 - val_loss: 3.8854 - val_acc: 0.3006\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.20999 to 0.30065, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 9/24\n",
            "781/781 [==============================] - 1260s 2s/step - loss: 4.0292 - acc: 0.2897 - val_loss: 3.8679 - val_acc: 0.3186\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.30065 to 0.31858, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 10/24\n",
            "781/781 [==============================] - 1260s 2s/step - loss: 3.9407 - acc: 0.3208 - val_loss: 3.5981 - val_acc: 0.3888\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.31858 to 0.38878, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 11/24\n",
            "781/781 [==============================] - 1260s 2s/step - loss: 3.8506 - acc: 0.3477 - val_loss: 3.5686 - val_acc: 0.3970\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.38878 to 0.39698, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 12/24\n",
            "781/781 [==============================] - 1260s 2s/step - loss: 3.7380 - acc: 0.3784 - val_loss: 3.3921 - val_acc: 0.4448\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.39698 to 0.44479, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 13/24\n",
            "781/781 [==============================] - 1259s 2s/step - loss: 3.6890 - acc: 0.3960 - val_loss: 3.4859 - val_acc: 0.4324\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.44479\n",
            "Epoch 14/24\n",
            "781/781 [==============================] - 1259s 2s/step - loss: 3.7480 - acc: 0.3913 - val_loss: 3.6663 - val_acc: 0.4066\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.44479\n",
            "Epoch 15/24\n",
            "781/781 [==============================] - 1258s 2s/step - loss: 3.8370 - acc: 0.3845 - val_loss: 3.6244 - val_acc: 0.4306\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.44479\n",
            "Epoch 16/24\n",
            "781/781 [==============================] - 1258s 2s/step - loss: 3.9515 - acc: 0.3797 - val_loss: 3.9649 - val_acc: 0.3845\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.44479\n",
            "Epoch 17/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.0665 - acc: 0.3755 - val_loss: 3.9659 - val_acc: 0.4072\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.44479\n",
            "Epoch 18/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.2170 - acc: 0.3731 - val_loss: 4.5771 - val_acc: 0.3226\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.44479\n",
            "Epoch 19/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.3119 - acc: 0.3793 - val_loss: 4.3162 - val_acc: 0.3989\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.44479\n",
            "Epoch 20/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.3254 - acc: 0.3968 - val_loss: 4.2296 - val_acc: 0.4241\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.44479\n",
            "Epoch 21/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.3269 - acc: 0.4147 - val_loss: 4.1991 - val_acc: 0.4487\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.44479 to 0.44874, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 22/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.3083 - acc: 0.4343 - val_loss: 4.1095 - val_acc: 0.4899\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.44874 to 0.48987, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 23/24\n",
            "781/781 [==============================] - 1257s 2s/step - loss: 4.2800 - acc: 0.4533 - val_loss: 4.0496 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.48987 to 0.51003, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n",
            "Epoch 24/24\n",
            "781/781 [==============================] - 1256s 2s/step - loss: 4.2312 - acc: 0.4747 - val_loss: 3.9833 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.51003 to 0.53262, saving model to ./drive/My Drive/Colab Notebooks/model1.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefa28942b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "eLxYOfqGDYgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 8 hours of running and saving the model, I shall run the new model from here after skipping the above part."
      ]
    },
    {
      "metadata": {
        "id": "JliA0PxJb6qj",
        "colab_type": "code",
        "outputId": "30ba5def-99d8-4845-f162-978f083a70d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 8 hours\n",
        "from keras.models import load_model\n",
        "new_model = load_model(\"./drive/My Drive/Colab Notebooks/model1.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d_uwpycYcLDA",
        "colab_type": "code",
        "outputId": "c8557e9f-14e0-4c3a-ca01-d3aab20f6a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1702
        }
      },
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.00006, step_size=4686., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer_2 = ModelCheckpoint(filepath=\"./drive/My Drive/Colab Notebooks/model2.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "# fit the model\n",
        "new_model.fit_generator(train_generator,\n",
        "                        epochs=epochs,\n",
        "                        steps_per_epoch= num_train // batch_size,\n",
        "                        validation_steps= num_validation // batch_size,\n",
        "                        validation_data=validation_generator,\n",
        "                        verbose=1, callbacks=[clr, checkpointer_2]\n",
        "                       )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            "781/781 [==============================] - 1192s 2s/step - loss: 4.1023 - acc: 0.5072 - val_loss: 3.7772 - val_acc: 0.5795\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57953, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 2/24\n",
            "781/781 [==============================] - 1180s 2s/step - loss: 4.0781 - acc: 0.5143 - val_loss: 3.7887 - val_acc: 0.5737\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.57953\n",
            "Epoch 3/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0725 - acc: 0.5165 - val_loss: 3.7946 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.57953\n",
            "Epoch 4/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0765 - acc: 0.5194 - val_loss: 3.8587 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.57953\n",
            "Epoch 5/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 4.0900 - acc: 0.5178 - val_loss: 3.8729 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.57953\n",
            "Epoch 6/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 4.1046 - acc: 0.5195 - val_loss: 3.8839 - val_acc: 0.5733\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.57953\n",
            "Epoch 7/24\n",
            "781/781 [==============================] - 1179s 2s/step - loss: 4.1115 - acc: 0.5245 - val_loss: 3.8964 - val_acc: 0.5726\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.57953\n",
            "Epoch 8/24\n",
            "781/781 [==============================] - 1179s 2s/step - loss: 4.0914 - acc: 0.5310 - val_loss: 3.8866 - val_acc: 0.5751\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.57953\n",
            "Epoch 9/24\n",
            "781/781 [==============================] - 1179s 2s/step - loss: 4.0767 - acc: 0.5385 - val_loss: 3.8663 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.57953 to 0.58651, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 10/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0573 - acc: 0.5458 - val_loss: 3.8548 - val_acc: 0.5896\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.58651 to 0.58965, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 11/24\n",
            "781/781 [==============================] - 1179s 2s/step - loss: 4.0398 - acc: 0.5500 - val_loss: 3.8476 - val_acc: 0.5933\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.58965 to 0.59329, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 12/24\n",
            "781/781 [==============================] - 1179s 2s/step - loss: 4.0228 - acc: 0.5585 - val_loss: 3.8213 - val_acc: 0.6036\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.59329 to 0.60363, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 13/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 4.0159 - acc: 0.5600 - val_loss: 3.8356 - val_acc: 0.6002\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.60363\n",
            "Epoch 14/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0198 - acc: 0.5598 - val_loss: 3.8584 - val_acc: 0.5964\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.60363\n",
            "Epoch 15/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0232 - acc: 0.5608 - val_loss: 3.8767 - val_acc: 0.5932\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.60363\n",
            "Epoch 16/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 4.0231 - acc: 0.5616 - val_loss: 3.8944 - val_acc: 0.5944\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.60363\n",
            "Epoch 17/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 4.0189 - acc: 0.5653 - val_loss: 3.9046 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.60363\n",
            "Epoch 18/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 4.0317 - acc: 0.5663 - val_loss: 3.9477 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.60363\n",
            "Epoch 19/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0287 - acc: 0.5702 - val_loss: 3.9422 - val_acc: 0.5941\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.60363\n",
            "Epoch 20/24\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.0051 - acc: 0.5783 - val_loss: 3.9382 - val_acc: 0.5922\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.60363\n",
            "Epoch 21/24\n",
            "781/781 [==============================] - 1176s 2s/step - loss: 3.9902 - acc: 0.5855 - val_loss: 3.9377 - val_acc: 0.5981\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.60363\n",
            "Epoch 22/24\n",
            "781/781 [==============================] - 1178s 2s/step - loss: 3.9685 - acc: 0.5919 - val_loss: 3.9214 - val_acc: 0.6063\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.60363 to 0.60626, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 23/24\n",
            "781/781 [==============================] - 1180s 2s/step - loss: 3.9517 - acc: 0.6004 - val_loss: 3.9175 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.60626 to 0.60636, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n",
            "Epoch 24/24\n",
            "781/781 [==============================] - 1181s 2s/step - loss: 3.9410 - acc: 0.6031 - val_loss: 3.9151 - val_acc: 0.6086\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.60636 to 0.60859, saving model to ./drive/My Drive/Colab Notebooks/model2.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4b106b77f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "e8EkvKXqkYMk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 16 hours of running and saving the model, I shall run the new model from here after skipping the above parts."
      ]
    },
    {
      "metadata": {
        "id": "QptoyV3vDz3y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Before further running the model, we shall analyse the accuracy of individual classes"
      ]
    },
    {
      "metadata": {
        "id": "rO9-EZlFcpU4",
        "colab_type": "code",
        "outputId": "c48331b7-d6c3-48be-e4f8-f49a14697b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 16 hours\n",
        "from keras.models import load_model\n",
        "extended_model = load_model(\"/content/drive/My Drive/Colab Notebooks/model2.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SXtmK6DPj3iy",
        "colab_type": "code",
        "outputId": "3d358905-22d5-48ca-aa03-3c6cc9062996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "pred=extended_model.predict_generator(validation_generator, steps= np.ceil(num_validation/batch_size), verbose=1)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 39s 495ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p9COv3Hbj6Ar",
        "colab_type": "code",
        "outputId": "2f0aef6c-1ef8-4be5-c58c-b7c04ca5069a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Predicted class indices of 1st 10 val images\n",
        "predicted_class_indices[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([107,  40,  89,  69, 132, 161,  99,  73, 145,  39])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "aTpKgD88j9QS",
        "colab_type": "code",
        "outputId": "b51a3c79-c9eb-4e72-b8eb-088fd3de8a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# True class indices of 1st 10 val images\n",
        "validation_generator.classes[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[107, 139, 140, 69, 69, 161, 147, 73, 145, 39]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "uFfekTdqj_pZ",
        "colab_type": "code",
        "outputId": "3731e3f6-2b5e-48df-f32f-5cc719ed3893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Predicted classes from their indices\n",
        "labels = (validation_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "predictions[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n03444034',\n",
              " 'n02231487',\n",
              " 'n03014705',\n",
              " 'n02808440',\n",
              " 'n03976657',\n",
              " 'n04399382',\n",
              " 'n03250847',\n",
              " 'n02823428',\n",
              " 'n04146614',\n",
              " 'n02226429']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "oinJxT-6kBtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Validation class names from words.txt\n",
        "import os\n",
        "class_to_name = dict()\n",
        "file = open('tiny-imagenet-200/words.txt','r')\n",
        "data= file.readlines()\n",
        "for line in data:\n",
        "  words = line.strip('\\n').split('\\t')\n",
        "  class_to_name[words[0]] = words[1].split(',')[0]\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qdo95ObikFyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Asserting Validation Class names from words.txt\n",
        "validation_class_names={}\n",
        "for _class in validation_generator.class_indices.keys():\n",
        "  validation_class_names.update({_class : class_to_name[_class]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDXz41tBkHqM",
        "colab_type": "code",
        "outputId": "82b5e29a-c19e-4fa8-9823-540c14e37e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3612
        }
      },
      "cell_type": "code",
      "source": [
        "# Classification Report of val classes\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(classification_report(validation_generator.classes, predicted_class_indices,\n",
        "                            #target_names=validation_generator.class_indices.keys(),\n",
        "                            target_names=validation_class_names.values(),\n",
        "                            digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                goldfish     0.8431    0.8600    0.8515        50\n",
            "European fire salamander     0.8571    0.8400    0.8485        50\n",
            "                bullfrog     0.6111    0.6600    0.6346        50\n",
            "             tailed frog     0.5532    0.5200    0.5361        50\n",
            "      American alligator     0.6591    0.5800    0.6170        50\n",
            "         boa constrictor     0.4510    0.4600    0.4554        50\n",
            "               trilobite     0.6774    0.8400    0.7500        50\n",
            "                scorpion     0.7500    0.5400    0.6279        50\n",
            "             black widow     0.8039    0.8200    0.8119        50\n",
            "               tarantula     0.6226    0.6600    0.6408        50\n",
            "               centipede     0.7111    0.6400    0.6737        50\n",
            "                   goose     0.7333    0.6600    0.6947        50\n",
            "                   koala     0.7885    0.8200    0.8039        50\n",
            "               jellyfish     0.7091    0.7800    0.7429        50\n",
            "             brain coral     0.6923    0.7200    0.7059        50\n",
            "                   snail     0.6667    0.5600    0.6087        50\n",
            "                    slug     0.5385    0.4200    0.4719        50\n",
            "                sea slug     0.7843    0.8000    0.7921        50\n",
            "        American lobster     0.5833    0.5600    0.5714        50\n",
            "           spiny lobster     0.7674    0.6600    0.7097        50\n",
            "             black stork     0.6984    0.8800    0.7788        50\n",
            "            king penguin     0.8333    0.7000    0.7609        50\n",
            "               albatross     0.7407    0.8000    0.7692        50\n",
            "                  dugong     0.7500    0.9000    0.8182        50\n",
            "               Chihuahua     0.5714    0.4000    0.4706        50\n",
            "       Yorkshire terrier     0.7857    0.8800    0.8302        50\n",
            "        golden retriever     0.5000    0.6000    0.5455        50\n",
            "      Labrador retriever     0.3774    0.4000    0.3883        50\n",
            "         German shepherd     0.5870    0.5400    0.5625        50\n",
            "         standard poodle     0.3469    0.3400    0.3434        50\n",
            "                   tabby     0.5319    0.5000    0.5155        50\n",
            "             Persian cat     0.8333    0.7000    0.7609        50\n",
            "            Egyptian cat     0.4423    0.4600    0.4510        50\n",
            "                  cougar     0.6154    0.4800    0.5393        50\n",
            "                    lion     0.8049    0.6600    0.7253        50\n",
            "              brown bear     0.5625    0.7200    0.6316        50\n",
            "                 ladybug     0.7885    0.8200    0.8039        50\n",
            "                     fly     0.5862    0.6800    0.6296        50\n",
            "                     bee     0.7170    0.7600    0.7379        50\n",
            "             grasshopper     0.6731    0.7000    0.6863        50\n",
            "           walking stick     0.5102    0.5000    0.5051        50\n",
            "               cockroach     0.5778    0.5200    0.5474        50\n",
            "                  mantis     0.5957    0.5600    0.5773        50\n",
            "               dragonfly     0.6364    0.5600    0.5957        50\n",
            "                 monarch     0.9583    0.9200    0.9388        50\n",
            "       sulphur butterfly     0.8776    0.8600    0.8687        50\n",
            "            sea cucumber     0.6000    0.6600    0.6286        50\n",
            "              guinea pig     0.7632    0.5800    0.6591        50\n",
            "                     hog     0.6552    0.3800    0.4810        50\n",
            "                      ox     0.4694    0.4600    0.4646        50\n",
            "                   bison     0.7255    0.7400    0.7327        50\n",
            "                 bighorn     0.5397    0.6800    0.6018        50\n",
            "                 gazelle     0.7736    0.8200    0.7961        50\n",
            "           Arabian camel     0.6170    0.5800    0.5979        50\n",
            "               orangutan     0.6909    0.7600    0.7238        50\n",
            "              chimpanzee     0.5231    0.6800    0.5913        50\n",
            "                  baboon     0.8611    0.6200    0.7209        50\n",
            "        African elephant     0.6964    0.7800    0.7358        50\n",
            "            lesser panda     0.8298    0.7800    0.8041        50\n",
            "                  abacus     0.7179    0.5600    0.6292        50\n",
            "           academic gown     0.6207    0.7200    0.6667        50\n",
            "                   altar     0.6531    0.6400    0.6465        50\n",
            "                   apron     0.4474    0.3400    0.3864        50\n",
            "                backpack     0.5536    0.6200    0.5849        50\n",
            "               bannister     0.3171    0.2600    0.2857        50\n",
            "              barbershop     0.3556    0.3200    0.3368        50\n",
            "                    barn     0.5574    0.6800    0.6126        50\n",
            "                  barrel     0.4667    0.4200    0.4421        50\n",
            "              basketball     0.7234    0.6800    0.7010        50\n",
            "                 bathtub     0.5957    0.5600    0.5773        50\n",
            "             beach wagon     0.6944    0.5000    0.5814        50\n",
            "                  beacon     0.6154    0.8000    0.6957        50\n",
            "                  beaker     0.6222    0.5600    0.5895        50\n",
            "             beer bottle     0.5294    0.5400    0.5347        50\n",
            "                  bikini     0.7442    0.6400    0.6882        50\n",
            "              binoculars     0.5472    0.5800    0.5631        50\n",
            "               birdhouse     0.7317    0.6000    0.6593        50\n",
            "                 bow tie     0.4595    0.3400    0.3908        50\n",
            "                   brass     0.7647    0.7800    0.7723        50\n",
            "                   broom     0.5000    0.3400    0.4048        50\n",
            "                  bucket     0.3043    0.2800    0.2917        50\n",
            "            bullet train     0.7586    0.8800    0.8148        50\n",
            "            butcher shop     0.6250    0.7000    0.6604        50\n",
            "                  candle     0.6383    0.6000    0.6186        50\n",
            "                  cannon     0.4906    0.5200    0.5049        50\n",
            "                cardigan     0.6122    0.6000    0.6061        50\n",
            "            cash machine     0.5660    0.6000    0.5825        50\n",
            "               CD player     0.5909    0.5200    0.5532        50\n",
            "                   chain     0.6176    0.4200    0.5000        50\n",
            "                   chest     0.5490    0.5600    0.5545        50\n",
            "      Christmas stocking     0.6957    0.6400    0.6667        50\n",
            "          cliff dwelling     0.5254    0.6200    0.5688        50\n",
            "       computer keyboard     0.7250    0.5800    0.6444        50\n",
            "           confectionery     0.6863    0.7000    0.6931        50\n",
            "             convertible     0.4909    0.5400    0.5143        50\n",
            "                   crane     0.7143    0.5000    0.5882        50\n",
            "                     dam     0.6111    0.4400    0.5116        50\n",
            "                    desk     0.5833    0.5600    0.5714        50\n",
            "            dining table     0.5781    0.7400    0.6491        50\n",
            "               drumstick     0.4474    0.3400    0.3864        50\n",
            "                dumbbell     0.3881    0.5200    0.4444        50\n",
            "                flagpole     0.5763    0.6800    0.6239        50\n",
            "                fountain     0.5000    0.6200    0.5536        50\n",
            "             freight car     0.6842    0.7800    0.7290        50\n",
            "              frying pan     0.5556    0.5000    0.5263        50\n",
            "                fur coat     0.4773    0.4200    0.4468        50\n",
            "                 gasmask     0.4894    0.4600    0.4742        50\n",
            "                 go-kart     0.6538    0.6800    0.6667        50\n",
            "                 gondola     0.8039    0.8200    0.8119        50\n",
            "               hourglass     0.5962    0.6200    0.6078        50\n",
            "                    iPod     0.6182    0.6800    0.6476        50\n",
            "              jinrikisha     0.6333    0.7600    0.6909        50\n",
            "                  kimono     0.3929    0.4400    0.4151        50\n",
            "               lampshade     0.5577    0.5800    0.5686        50\n",
            "              lawn mower     0.6364    0.4200    0.5060        50\n",
            "                lifeboat     0.8667    0.7800    0.8211        50\n",
            "               limousine     0.6604    0.7000    0.6796        50\n",
            "        magnetic compass     0.7500    0.7200    0.7347        50\n",
            "                 maypole     0.6393    0.7800    0.7027        50\n",
            "        military uniform     0.3333    0.3400    0.3366        50\n",
            "               miniskirt     0.4194    0.5200    0.4643        50\n",
            "              moving van     0.7143    0.6000    0.6522        50\n",
            "                    nail     0.4694    0.4600    0.4646        50\n",
            "              neck brace     0.3857    0.5400    0.4500        50\n",
            "                 obelisk     0.6949    0.8200    0.7523        50\n",
            "                    oboe     0.4286    0.4200    0.4242        50\n",
            "                   organ     0.5574    0.6800    0.6126        50\n",
            "           parking meter     0.5600    0.5600    0.5600        50\n",
            "               pay-phone     0.5085    0.6000    0.5505        50\n",
            "            picket fence     0.6429    0.7200    0.6792        50\n",
            "             pill bottle     0.4677    0.5800    0.5179        50\n",
            "                 plunger     0.2500    0.1600    0.1951        50\n",
            "                    pole     0.3333    0.2000    0.2500        50\n",
            "              police van     0.7647    0.7800    0.7723        50\n",
            "                  poncho     0.6170    0.5800    0.5979        50\n",
            "              pop bottle     0.3590    0.2800    0.3146        50\n",
            "          potter's wheel     0.4306    0.6200    0.5082        50\n",
            "              projectile     0.4490    0.4400    0.4444        50\n",
            "            punching bag     0.3889    0.4200    0.4038        50\n",
            "                    reel     0.3947    0.3000    0.3409        50\n",
            "            refrigerator     0.5952    0.5000    0.5435        50\n",
            "          remote control     0.5814    0.5000    0.5376        50\n",
            "           rocking chair     0.7500    0.4800    0.5854        50\n",
            "              rugby ball     0.7818    0.8600    0.8190        50\n",
            "                  sandal     0.5385    0.7000    0.6087        50\n",
            "              school bus     0.7581    0.9400    0.8393        50\n",
            "              scoreboard     0.8163    0.8000    0.8081        50\n",
            "          sewing machine     0.6667    0.4800    0.5581        50\n",
            "                 snorkel     0.5517    0.6400    0.5926        50\n",
            "                    sock     0.6349    0.8000    0.7080        50\n",
            "                sombrero     0.6842    0.5200    0.5909        50\n",
            "            space heater     0.5000    0.4800    0.4898        50\n",
            "              spider web     0.6230    0.7600    0.6847        50\n",
            "              sports car     0.5128    0.8000    0.6250        50\n",
            "       steel arch bridge     0.6800    0.6800    0.6800        50\n",
            "               stopwatch     0.7447    0.7000    0.7216        50\n",
            "              sunglasses     0.6875    0.4400    0.5366        50\n",
            "       suspension bridge     0.5323    0.6600    0.5893        50\n",
            "         swimming trunks     0.4375    0.4200    0.4286        50\n",
            "                 syringe     0.5000    0.2200    0.3056        50\n",
            "                  teapot     0.4576    0.5400    0.4954        50\n",
            "                   teddy     0.6939    0.6800    0.6869        50\n",
            "                  thatch     0.6744    0.5800    0.6237        50\n",
            "                   torch     0.6429    0.5400    0.5870        50\n",
            "                 tractor     0.6111    0.6600    0.6346        50\n",
            "          triumphal arch     0.7719    0.8800    0.8224        50\n",
            "              trolleybus     0.7797    0.9200    0.8440        50\n",
            "               turnstile     0.4717    0.5000    0.4854        50\n",
            "                umbrella     0.2727    0.2400    0.2553        50\n",
            "                vestment     0.6182    0.6800    0.6476        50\n",
            "                 viaduct     0.6852    0.7400    0.7115        50\n",
            "              volleyball     0.7091    0.7800    0.7429        50\n",
            "               water jug     0.3000    0.2400    0.2667        50\n",
            "             water tower     0.7500    0.8400    0.7925        50\n",
            "                     wok     0.6000    0.6000    0.6000        50\n",
            "            wooden spoon     0.3103    0.1800    0.2278        50\n",
            "              comic book     0.7959    0.7800    0.7879        50\n",
            "                   plate     0.4754    0.5800    0.5225        50\n",
            "               guacamole     0.7917    0.7600    0.7755        50\n",
            "               ice cream     0.4098    0.5000    0.4505        50\n",
            "               ice lolly     0.4000    0.4000    0.4000        50\n",
            "                 pretzel     0.5962    0.6200    0.6078        50\n",
            "           mashed potato     0.5652    0.5200    0.5417        50\n",
            "             cauliflower     0.8000    0.6400    0.7111        50\n",
            "             bell pepper     0.7679    0.8600    0.8113        50\n",
            "                mushroom     0.7755    0.7600    0.7677        50\n",
            "                  orange     0.6977    0.6000    0.6452        50\n",
            "                   lemon     0.6122    0.6000    0.6061        50\n",
            "                  banana     0.5484    0.6800    0.6071        50\n",
            "             pomegranate     0.7455    0.8200    0.7810        50\n",
            "               meat loaf     0.5370    0.5800    0.5577        50\n",
            "                   pizza     0.7755    0.7600    0.7677        50\n",
            "                  potpie     0.6538    0.6800    0.6667        50\n",
            "                espresso     0.6324    0.8600    0.7288        50\n",
            "                     alp     0.6034    0.7000    0.6481        50\n",
            "                   cliff     0.5556    0.6000    0.5769        50\n",
            "              coral reef     0.5968    0.7400    0.6607        50\n",
            "                lakeside     0.4651    0.4000    0.4301        50\n",
            "                seashore     0.5500    0.6600    0.6000        50\n",
            "                   acorn     0.6122    0.6000    0.6061        50\n",
            "\n",
            "               micro avg     0.6092    0.6092    0.6092     10000\n",
            "               macro avg     0.6101    0.6092    0.6049     10000\n",
            "            weighted avg     0.6101    0.6092    0.6049     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w94eggUWkJ3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class Weight dictionary\n",
        "\"\"\"class_weights = {0:1,1:1,2:1,3:1,4:1,5:1,6:1,7:1,8:1,9:1,10:1,\n",
        "                 11:1,12:1,13:1,14:1,15:1,16:1,17:1,18:1,19:1,20:1,\n",
        "                 21:1,22:1,23:1,24:1,25:1,26:1,27:1,28:1,29:1,30:1,\n",
        "                 31:1,32:1,33:1,34:1,35:1,36:1,37:1,38:1,39:1,40:1,\n",
        "                 41:1,42:1,43:1,44:1,45:1,46:1,47:1,48:1,49:1,50:1,\n",
        "                 51:1,52:1,53:1,54:1,55:1,56:1,57:1,58:1,59:1,60:1,\n",
        "                 61:1,62:1,63:1,64:1.2,65:1,66:1,67:1,68:1,69:1,70:1,\n",
        "                 71:1,72:1,73:1,74:1,75:1,76:1,77:1,78:1,79:1,80:1.2,\n",
        "                 81:1,82:1,83:1,84:1,85:1,86:1,87:1,88:1,89:1,90:1,\n",
        "                 91:1,92:1,93:1,94:1,95:1,96:1,97:1,98:1,99:1,100:1,\n",
        "                 101:1,102:1,103:1,104:1,105:1,106:1,107:1,108:1,109:1,110:1,\n",
        "                 111:1,112:1,113:1,114:1,115:1,116:1,117:1,118:1,119:1,120:1,\n",
        "                 121:1,122:1,123:1,124:1,125:1,126:1,127:1,128:1,129:1,130:1,\n",
        "                 131:1.2,132:1,133:1,134:1,135:1,136:1,137:1,138:1,139:1,140:1,\n",
        "                 141:1,142:1,143:1,144:1,145:1,146:1,147:1,148:1,149:1,150:1,\n",
        "                 151:1,152:1,153:1,154:1,155:1,156:1,157:1,158:1,159:1,160:1,\n",
        "                 161:1,162:1,163:1,164:1,165:1,166:1,167:1,168:1.2,169:1,170:1,\n",
        "                 171:1,172:1.2,173:1,174:1,175:1.2,176:1,177:1,178:1,179:1,180:1,\n",
        "                 181:1,182:1,183:1,184:1,185:1,186:1,187:1,188:1,189:1,190:1,\n",
        "                 191:1,192:1,193:1,194:1,195:1,196:1,197:1,198:1,199:1,\n",
        "                }\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_6TWZ2-kOt6",
        "colab_type": "code",
        "outputId": "0eaef696-5b7b-420b-ca1b-2476ca7d2808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1702
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.00006, step_size=3128., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer_3 = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/model3.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "# fit the model\n",
        "extended_model.fit_generator(train_generator,\n",
        "                             epochs=epochs,\n",
        "                             steps_per_epoch= np.ceil(num_train/batch_size),\n",
        "                             validation_steps= np.ceil(num_validation/batch_size),\n",
        "                             validation_data=validation_generator,\n",
        "                             verbose=1, callbacks=[clr, checkpointer_3],\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            "782/782 [==============================] - 1233s 2s/step - loss: 4.0270 - acc: 0.5835 - val_loss: 3.9649 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.60600, saving model to /content/drive/My Drive/Colab Notebooks/model3.hdf5\n",
            "Epoch 2/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.0542 - acc: 0.5800 - val_loss: 4.0233 - val_acc: 0.5931\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.60600\n",
            "Epoch 3/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.0802 - acc: 0.5772 - val_loss: 4.0899 - val_acc: 0.5814\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.60600\n",
            "Epoch 4/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.1185 - acc: 0.5719 - val_loss: 4.1946 - val_acc: 0.5678\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.60600\n",
            "Epoch 5/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.1382 - acc: 0.5731 - val_loss: 4.1346 - val_acc: 0.5799\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.60600\n",
            "Epoch 6/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.1008 - acc: 0.5844 - val_loss: 4.0813 - val_acc: 0.5994\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.60600\n",
            "Epoch 7/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.0679 - acc: 0.5998 - val_loss: 4.0438 - val_acc: 0.6066\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.60600 to 0.60660, saving model to /content/drive/My Drive/Colab Notebooks/model3.hdf5\n",
            "Epoch 8/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.0349 - acc: 0.6084 - val_loss: 4.0248 - val_acc: 0.6126\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.60660 to 0.61260, saving model to /content/drive/My Drive/Colab Notebooks/model3.hdf5\n",
            "Epoch 9/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.0275 - acc: 0.6128 - val_loss: 4.0379 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61260\n",
            "Epoch 10/24\n",
            "782/782 [==============================] - 1213s 2s/step - loss: 4.0476 - acc: 0.6080 - val_loss: 4.0833 - val_acc: 0.6023\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.61260\n",
            "Epoch 11/24\n",
            "782/782 [==============================] - 1214s 2s/step - loss: 4.0776 - acc: 0.6027 - val_loss: 4.1125 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.61260\n",
            "Epoch 12/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.1148 - acc: 0.5987 - val_loss: 4.1814 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.61260\n",
            "Epoch 13/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.1356 - acc: 0.5961 - val_loss: 4.1645 - val_acc: 0.5947\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.61260\n",
            "Epoch 14/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.1139 - acc: 0.6053 - val_loss: 4.1670 - val_acc: 0.6020\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.61260\n",
            "Epoch 15/24\n",
            "782/782 [==============================] - 1217s 2s/step - loss: 4.0844 - acc: 0.6130 - val_loss: 4.1104 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.61260\n",
            "Epoch 16/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.0487 - acc: 0.6221 - val_loss: 4.0982 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.61260 to 0.61670, saving model to /content/drive/My Drive/Colab Notebooks/model3.hdf5\n",
            "Epoch 17/24\n",
            "782/782 [==============================] - 1216s 2s/step - loss: 4.0241 - acc: 0.6326 - val_loss: 4.1038 - val_acc: 0.6156\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.61670\n",
            "Epoch 18/24\n",
            "782/782 [==============================] - 1216s 2s/step - loss: 4.0267 - acc: 0.6333 - val_loss: 4.1269 - val_acc: 0.6124\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.61670\n",
            "Epoch 19/24\n",
            "782/782 [==============================] - 1216s 2s/step - loss: 4.0269 - acc: 0.6347 - val_loss: 4.1696 - val_acc: 0.6077\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.61670\n",
            "Epoch 20/24\n",
            "782/782 [==============================] - 1216s 2s/step - loss: 4.0308 - acc: 0.6348 - val_loss: 4.1903 - val_acc: 0.5992\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.61670\n",
            "Epoch 21/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.0376 - acc: 0.6349 - val_loss: 4.1894 - val_acc: 0.6091\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.61670\n",
            "Epoch 22/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.0318 - acc: 0.6392 - val_loss: 4.1781 - val_acc: 0.6127\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.61670\n",
            "Epoch 23/24\n",
            "782/782 [==============================] - 1215s 2s/step - loss: 4.0233 - acc: 0.6446 - val_loss: 4.1581 - val_acc: 0.6174\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.61670 to 0.61740, saving model to /content/drive/My Drive/Colab Notebooks/model3.hdf5\n",
            "Epoch 24/24\n",
            "782/782 [==============================] - 1216s 2s/step - loss: 4.0245 - acc: 0.6440 - val_loss: 4.1576 - val_acc: 0.6160\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.61740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c599d5a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "mQUkQQMjJVLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ### After 24 hours of running and saving the model, I shall run the new model from here after skipping the above parts."
      ]
    },
    {
      "metadata": {
        "id": "tDOVKOk_KDob",
        "colab_type": "code",
        "outputId": "3ffc329a-8c45-4fee-b074-54d7bba3f363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 24 hours\n",
        "from keras.models import load_model\n",
        "extended_model = load_model(\"/content/drive/My Drive/Colab Notebooks/model3.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXn0LmC6juT3",
        "colab_type": "code",
        "outputId": "33505379-9ec5-45d4-e9df-1c6d82b25a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "clr = CyclicLR(base_lr=0.000001, max_lr=0.000006, step_size=1564., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer_4 = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/model4.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "# fit the model\n",
        "extended_model.fit_generator(train_generator,\n",
        "                             epochs=12,\n",
        "                             steps_per_epoch= np.ceil(num_train/batch_size),\n",
        "                             validation_steps= np.ceil(num_validation/batch_size),\n",
        "                             validation_data=validation_generator,\n",
        "                             verbose=1, callbacks=[clr, checkpointer_4]\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "782/782 [==============================] - 1300s 2s/step - loss: 4.0547 - acc: 0.6351 - val_loss: 4.1352 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.62160, saving model to /content/drive/My Drive/Colab Notebooks/model4.hdf5\n",
            "Epoch 2/12\n",
            "782/782 [==============================] - 1275s 2s/step - loss: 4.0245 - acc: 0.6460 - val_loss: 4.1414 - val_acc: 0.6205\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.62160\n",
            "Epoch 3/12\n",
            "782/782 [==============================] - 1275s 2s/step - loss: 3.9912 - acc: 0.6541 - val_loss: 4.1333 - val_acc: 0.6227\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.62160 to 0.62270, saving model to /content/drive/My Drive/Colab Notebooks/model4.hdf5\n",
            "Epoch 4/12\n",
            "782/782 [==============================] - 1275s 2s/step - loss: 3.9535 - acc: 0.6650 - val_loss: 4.1327 - val_acc: 0.6214\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.62270\n",
            "Epoch 5/12\n",
            "782/782 [==============================] - 1276s 2s/step - loss: 3.9429 - acc: 0.6691 - val_loss: 4.1337 - val_acc: 0.6217\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.62270\n",
            "Epoch 6/12\n",
            "782/782 [==============================] - 1276s 2s/step - loss: 3.9465 - acc: 0.6663 - val_loss: 4.1368 - val_acc: 0.6223\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.62270\n",
            "Epoch 7/12\n",
            "782/782 [==============================] - 1276s 2s/step - loss: 3.9631 - acc: 0.6629 - val_loss: 4.1362 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.62270\n",
            "Epoch 8/12\n",
            "782/782 [==============================] - 1276s 2s/step - loss: 3.9831 - acc: 0.6570 - val_loss: 4.1340 - val_acc: 0.6234\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.62270 to 0.62340, saving model to /content/drive/My Drive/Colab Notebooks/model4.hdf5\n",
            "Epoch 9/12\n",
            "782/782 [==============================] - 1275s 2s/step - loss: 3.9927 - acc: 0.6545 - val_loss: 4.1339 - val_acc: 0.6243\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.62340 to 0.62430, saving model to /content/drive/My Drive/Colab Notebooks/model4.hdf5\n",
            "Epoch 10/12\n",
            "782/782 [==============================] - 1275s 2s/step - loss: 3.9802 - acc: 0.6585 - val_loss: 4.1408 - val_acc: 0.6203\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.62430\n",
            "Epoch 11/12\n",
            "782/782 [==============================] - 1276s 2s/step - loss: 3.9732 - acc: 0.6600 - val_loss: 4.1372 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.62430\n",
            "Epoch 12/12\n",
            "782/782 [==============================] - 1276s 2s/step - loss: 3.9654 - acc: 0.6640 - val_loss: 4.1380 - val_acc: 0.6224\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.62430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87598eb860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Gctl0JQEERwN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 24 hours of running and saving the model, I shall run the new model from here after skipping the above parts."
      ]
    },
    {
      "metadata": {
        "id": "ka_Y06r2KNXh",
        "colab_type": "code",
        "outputId": "bafca02f-bc88-4182-c41c-8309becdd039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 28 hours\n",
        "from keras.models import load_model\n",
        "extended_model = load_model(\"/content/drive/My Drive/Colab  Notebooks/model4.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oSQ83f6NbDbF",
        "colab_type": "code",
        "outputId": "8d81f197-16e9-4fc2-b5b3-08b7d3932fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.00006, step_size=1564., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer_5 = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/model5.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "# fit the model\n",
        "extended_model.fit_generator(train_generator,\n",
        "                             epochs=12,\n",
        "                             steps_per_epoch= np.ceil(num_train/batch_size),\n",
        "                             validation_steps= np.ceil(num_validation/batch_size),\n",
        "                             validation_data=validation_generator,\n",
        "                             verbose=1, callbacks=[clr, checkpointer_5]\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "782/782 [==============================] - 1189s 2s/step - loss: 4.0826 - acc: 0.6316 - val_loss: 4.3063 - val_acc: 0.5952\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.59520, saving model to /content/drive/My Drive/Colab Notebooks/model5.hdf5\n",
            "Epoch 2/12\n",
            "782/782 [==============================] - 1170s 1s/step - loss: 4.1577 - acc: 0.6179 - val_loss: 4.4593 - val_acc: 0.5657\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.59520\n",
            "Epoch 3/12\n",
            "782/782 [==============================] - 1171s 1s/step - loss: 4.1736 - acc: 0.6200 - val_loss: 4.3616 - val_acc: 0.5924\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.59520\n",
            "Epoch 4/12\n",
            "782/782 [==============================] - 1171s 1s/step - loss: 4.0826 - acc: 0.6468 - val_loss: 4.2524 - val_acc: 0.6140\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.59520 to 0.61400, saving model to /content/drive/My Drive/Colab Notebooks/model5.hdf5\n",
            "Epoch 5/12\n",
            "782/782 [==============================] - 1171s 1s/step - loss: 4.0466 - acc: 0.6586 - val_loss: 4.2914 - val_acc: 0.6080\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61400\n",
            "Epoch 6/12\n",
            "782/782 [==============================] - 1170s 1s/step - loss: 4.0831 - acc: 0.6498 - val_loss: 4.3521 - val_acc: 0.5991\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61400\n",
            "Epoch 7/12\n",
            "782/782 [==============================] - 1170s 1s/step - loss: 4.1192 - acc: 0.6442 - val_loss: 4.3168 - val_acc: 0.6087\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61400\n",
            "Epoch 8/12\n",
            "782/782 [==============================] - 1170s 1s/step - loss: 4.1106 - acc: 0.6483 - val_loss: 4.2744 - val_acc: 0.6182\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.61400 to 0.61820, saving model to /content/drive/My Drive/Colab Notebooks/model5.hdf5\n",
            "Epoch 9/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.1032 - acc: 0.6526 - val_loss: 4.2937 - val_acc: 0.6138\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61820\n",
            "Epoch 10/12\n",
            "782/782 [==============================] - 1173s 1s/step - loss: 4.1174 - acc: 0.6503 - val_loss: 4.3620 - val_acc: 0.5999\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.61820\n",
            "Epoch 11/12\n",
            "782/782 [==============================] - 1204s 2s/step - loss: 4.1202 - acc: 0.6517 - val_loss: 4.3146 - val_acc: 0.6124\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.61820\n",
            "Epoch 12/12\n",
            "782/782 [==============================] - 1203s 2s/step - loss: 4.1001 - acc: 0.6611 - val_loss: 4.3117 - val_acc: 0.6183\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.61820 to 0.61830, saving model to /content/drive/My Drive/Colab Notebooks/model5.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89027d6278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "ZmrJme0wEWs0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 32 hours of running and saving the model, I shall run the new model from here after skipping the above parts."
      ]
    },
    {
      "metadata": {
        "id": "s30oJ3RHbNue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the model after 32 hours\n",
        "from keras.models import load_model\n",
        "extended_model = load_model(\"/content/drive/My Drive/Colab Notebooks/model5.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VP9TbcZOlbog",
        "colab_type": "code",
        "outputId": "a2d39777-90cb-420d-d56f-8b39d121d843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "clr = CyclicLR(base_lr=0.0000001, max_lr=0.0000006, step_size=1564., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer_6 = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/model6.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "# fit the model\n",
        "extended_model.fit_generator(train_generator,\n",
        "                             epochs=12,\n",
        "                             steps_per_epoch= np.ceil(num_train/batch_size),\n",
        "                             validation_steps= np.ceil(num_validation/batch_size),\n",
        "                             validation_data=validation_generator,\n",
        "                             verbose=1, callbacks=[clr, checkpointer_6]\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "782/782 [==============================] - 1212s 2s/step - loss: 4.0801 - acc: 0.6662 - val_loss: 4.2796 - val_acc: 0.6258\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.62580, saving model to /content/drive/My Drive/Colab Notebooks/model6.hdf5\n",
            "Epoch 2/12\n",
            "782/782 [==============================] - 1203s 2s/step - loss: 4.0799 - acc: 0.6668 - val_loss: 4.2786 - val_acc: 0.6258\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.62580\n",
            "Epoch 3/12\n",
            "782/782 [==============================] - 1201s 2s/step - loss: 4.0770 - acc: 0.6670 - val_loss: 4.2744 - val_acc: 0.6266\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.62580 to 0.62660, saving model to /content/drive/My Drive/Colab Notebooks/model6.hdf5\n",
            "Epoch 4/12\n",
            "782/782 [==============================] - 1178s 2s/step - loss: 4.0737 - acc: 0.6657 - val_loss: 4.2751 - val_acc: 0.6261\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.62660\n",
            "Epoch 5/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0584 - acc: 0.6707 - val_loss: 4.2744 - val_acc: 0.6260\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.62660\n",
            "Epoch 6/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0519 - acc: 0.6719 - val_loss: 4.2733 - val_acc: 0.6265\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.62660\n",
            "Epoch 7/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0366 - acc: 0.6770 - val_loss: 4.2740 - val_acc: 0.6268\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.62660 to 0.62680, saving model to /content/drive/My Drive/Colab Notebooks/model6.hdf5\n",
            "Epoch 8/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0196 - acc: 0.6824 - val_loss: 4.2732 - val_acc: 0.6272\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.62680 to 0.62720, saving model to /content/drive/My Drive/Colab Notebooks/model6.hdf5\n",
            "Epoch 9/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0206 - acc: 0.6811 - val_loss: 4.2737 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.62720 to 0.62730, saving model to /content/drive/My Drive/Colab Notebooks/model6.hdf5\n",
            "Epoch 10/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0215 - acc: 0.6819 - val_loss: 4.2737 - val_acc: 0.6266\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.62730\n",
            "Epoch 11/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0257 - acc: 0.6809 - val_loss: 4.2734 - val_acc: 0.6271\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.62730\n",
            "Epoch 12/12\n",
            "782/782 [==============================] - 1169s 1s/step - loss: 4.0683 - acc: 0.6683 - val_loss: 4.2734 - val_acc: 0.6272\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.62730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8900a21e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "xhS2U_LcEfJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Top Validation Accuracy : 62.73%"
      ]
    },
    {
      "metadata": {
        "id": "Jp3Ux8MH_JDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}