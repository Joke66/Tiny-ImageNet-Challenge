{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zoheb_Assignment_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohebAbai/Tiny-ImageNet-Challenge/blob/master/TinyImageNet_Network_2_with_additional_methods_without_clr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FTAbvlllVRoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Submitted by : Zoheb Abai (EIP 3 Batch 1)**"
      ]
    },
    {
      "metadata": {
        "id": "rbFWKENPNFan",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing libraries and Downloading Dataset"
      ]
    },
    {
      "metadata": {
        "id": "YubpnYKoypBB",
        "colab_type": "code",
        "outputId": "2ff8e10e-558f-44fb-9a56-eb8533899d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Installing and importing keras\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "62KoctD6ywEu",
        "colab_type": "code",
        "outputId": "1882fe87-ddd0-47dc-e881-e468dca6571d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "## Downloading the dataset \n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-05 07:16:12--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  61.1MB/s    in 5.0s    \n",
            "\n",
            "2019-04-05 07:16:17 (47.7 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WSZgA_Uqy2YR",
        "colab_type": "code",
        "outputId": "be02ae92-c9d0-49d6-dc6a-6c4d6c956e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Unzipping it \n",
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  tiny-imagenet-200\ttiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qFR63No3huMc",
        "colab_type": "code",
        "outputId": "bfad604c-0297-49a0-9eaa-7e246c1fbd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Mounting google drive for saving models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VN6Kypan8heI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNE31zhxzA8J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SeparableConv2D\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "#from keras_contrib.callbacks import CyclicLR\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# random seed\n",
        "np.random.seed(seed=101)\n",
        "ia.seed(101)\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "# input image dimensions\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "channels = 3\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 200\n",
        "epochs = 36\n",
        "num_train = 100000\n",
        "num_validation = 10000\n",
        "\n",
        "# Callbacks\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.000001)\n",
        "#clr = CyclicLR(base_lr=0.00001, max_lr=0.001, step_size=852., mode='triangular2') #Cyclic learning rate\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAQD-38dzG_t",
        "colab_type": "code",
        "outputId": "4f3885b2-ca76-4da9-f356-aeba6ad246b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "# Dropping the annotations from txt file as its not required for this project\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, \n",
        "                       names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "val_data.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_0.JPEG</td>\n",
              "      <td>n03444034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_1.JPEG</td>\n",
              "      <td>n04067472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_2.JPEG</td>\n",
              "      <td>n04070727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         File      Class\n",
              "0  val_0.JPEG  n03444034\n",
              "1  val_1.JPEG  n04067472\n",
              "2  val_2.JPEG  n04070727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "HT3B2S-rOFaE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "kAtL6zG4PvUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining Customized Imagedatagenerator using imgaug library\n",
        "def CustomImageDataGen(input_img):\n",
        "  # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
        "  # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n",
        "  # image.\n",
        "  sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "  \n",
        "  seq = iaa.Sequential([\n",
        "      iaa.Fliplr(0.5), # horizontal flips\n",
        "      iaa.Flipud(0.2), # vertical flips\n",
        "      \n",
        "      # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "      # But we only blur about 50% of all images.\n",
        "      sometimes(iaa.GaussianBlur(sigma=(0, 2.0))),\n",
        "      \n",
        "      # crop images by -10% to 20% of their height/width\n",
        "      sometimes(iaa.CropAndPad(\n",
        "          percent=(-0.1, 0.2),\n",
        "          pad_mode=ia.ALL,\n",
        "          pad_cval=(0, 255)\n",
        "        )),\n",
        "      \n",
        "      # Apply affine transformations to some of the images\n",
        "      # - scale to 80-120% of image height/width (each axis independently)\n",
        "      # - translate by -20 to +20 relative to height/width (per axis)\n",
        "      # - rotate by -45 to +45 degrees\n",
        "      # - shear by -16 to +16 degrees\n",
        "      # - order: use nearest neighbour or bilinear interpolation (fast)\n",
        "      # - mode: use any available mode to fill newly created pixels\n",
        "      #         see API or scikit-image for which modes are available\n",
        "      # - cval: if the mode is constant, then use a random brightness\n",
        "      #         for the newly created pixels (e.g. sometimes black,\n",
        "      #         sometimes white)\n",
        "      sometimes(iaa.Affine(\n",
        "          scale={\"x\": (0.8, 1.5), \"y\": (0.8, 1.5)},\n",
        "          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "          rotate=(-45, 45),\n",
        "          shear=(-16, 16),\n",
        "          order=[0, 1],\n",
        "          cval=(0, 255),\n",
        "          mode=ia.ALL\n",
        "      )),\n",
        "      \n",
        "      #drop 2-5% percent of the original size, leading to large dropped\n",
        "      # rectangles.\n",
        "      sometimes(iaa.CoarseDropout(\n",
        "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
        "                        per_channel=0.2\n",
        "                    )),\n",
        "      # Add gaussian noise.\n",
        "      # For 50% of all images, we sample the noise once per pixel.\n",
        "      # For the other 50% of all images, we sample the noise per pixel AND\n",
        "      # channel. This can change the color (not only brightness) of the\n",
        "      # pixels.\n",
        "      #iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "      \n",
        "      # Make some images brighter and some darker.\n",
        "      # In 20% of all cases, we sample the multiplier once per channel,\n",
        "      # which can end up changing the color of the images.\n",
        "      sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.2)),\n",
        "      \n",
        "      # Improve or worsen the contrast of images.\n",
        "      sometimes(iaa.ContrastNormalization((0.75, 1.5), per_channel=0.5)),  \n",
        "      \n",
        "      # Converts images from colorspace to grayscale and mixes with the original \n",
        "      # image using alpha A\n",
        "      #sometimes(iaa.Grayscale(alpha=(0.0, 1.0))),\n",
        "     ],\n",
        "     # do all of the above augmentations in random order\n",
        "     random_order = True) # apply augmenters in random order\n",
        "  \n",
        "  output_img = seq.augment_image(input_img)\n",
        "  return output_img\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function = CustomImageDataGen)\n",
        "valid_datagen = ImageDataGenerator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozBi8_545Ekj",
        "colab_type": "code",
        "outputId": "cb364496-c738-4b88-a6b5-14a67a6591df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Training set generator\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', \n",
        "                                                    target_size=(img_width, img_height), \n",
        "                                                    batch_size=batch_size, \n",
        "                                                    class_mode='categorical', \n",
        "                                                    shuffle=True, \n",
        "                                                    #shuffle=False, #Use only for viewing predictions after 100 epochs\n",
        "                                                    seed=101)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KKU2EySA5H0j",
        "colab_type": "code",
        "outputId": "fe6b45e2-941c-4d13-8b5c-d103a58e81be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Validation set generator\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', \n",
        "                                                         x_col='File', y_col='Class', \n",
        "                                                         target_size=(img_width, img_height),\n",
        "                                                         class_mode='categorical', \n",
        "                                                         batch_size=batch_size, \n",
        "                                                         shuffle=False, seed=101)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ACItBok2Oaym",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Building and Compilation"
      ]
    },
    {
      "metadata": {
        "id": "6LCoCBKSdtZH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Below is the custom Resnet Model, where architecture is inspired from Wide-Resnet and Resnet-18 keras models. As required for the project followings have not been used :\n",
        "1. 1x1 for an increasing number of channels\n",
        "2. dropout\n",
        "3. fully connected layers\n",
        "4. test dataset for training\n",
        "5. pre-trained model/weights\n",
        "6. someone else's code "
      ]
    },
    {
      "metadata": {
        "id": "oJ5ngcVerXdh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Note : For running the new model after 12 hours of run, don't run beyond this, as the saved model contains model architecture, weights and optimizer."
      ]
    },
    {
      "metadata": {
        "id": "i2RWFJYhsN_F",
        "colab_type": "code",
        "outputId": "0e8e8f09-8965-4c4f-c3db-9faf2fe771f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# Model building\n",
        "input = Input(shape=(img_height, img_width, channels))\n",
        "\n",
        "# Block 1\n",
        "layer0 = Conv2D(32, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(input)\n",
        "layer0 = BatchNormalization()(layer0)\n",
        "layer0 = Activation('relu')(layer0)\n",
        "\n",
        "skip_connection_1 = layer0\n",
        "\n",
        "# Block 2\n",
        "\n",
        "layer1 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer0)\n",
        "layer1 = BatchNormalization()(layer1)\n",
        "layer1 = Activation('relu')(layer1)\n",
        "\n",
        "layer2 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer1)\n",
        "layer2 = BatchNormalization()(layer2)\n",
        "layer2 = Activation('relu')(layer2)\n",
        "\n",
        "layer3 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer2)\n",
        "layer3 = BatchNormalization()(layer3)\n",
        "layer3 = Activation('relu')(layer3)\n",
        "\n",
        "layer4 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer3)\n",
        "layer4 = BatchNormalization()(layer4)\n",
        "layer4 = Activation('relu')(layer4)\n",
        "\n",
        "layer5 = concatenate([skip_connection_1, layer4])\n",
        "layer5 = BatchNormalization()(layer5)\n",
        "layer5 = Activation('relu')(layer5)\n",
        "layer5 = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
        "\n",
        "skip_connection_2 = layer5\n",
        "\n",
        "# Block 3\n",
        "\n",
        "layer6 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer5)\n",
        "layer6 = BatchNormalization()(layer6)\n",
        "layer6 = Activation('relu')(layer6)\n",
        "\n",
        "layer7 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer6)\n",
        "layer7 = BatchNormalization()(layer7)\n",
        "layer7 = Activation('relu')(layer7)\n",
        "\n",
        "layer8 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer7)\n",
        "layer8 = BatchNormalization()(layer8)\n",
        "layer8 = Activation('relu')(layer8)\n",
        "\n",
        "layer9 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer8)\n",
        "layer9 = BatchNormalization()(layer9)\n",
        "layer9 = Activation('relu')(layer9)\n",
        "\n",
        "layer10 = concatenate([skip_connection_2, layer9])\n",
        "layer10 = BatchNormalization()(layer10)\n",
        "layer10 = Activation('relu')(layer10)\n",
        "layer10 = MaxPooling2D(pool_size=(2, 2))(layer10)\n",
        "\n",
        "skip_connection_3 = layer10\n",
        "\n",
        "\n",
        "# Block 4\n",
        "\n",
        "layer11 = Conv2D(512, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer10)\n",
        "layer11 = BatchNormalization()(layer11)\n",
        "layer11 = Activation('relu')(layer11)\n",
        "\n",
        "layer12 = Conv2D(512, (3,3), padding='same', kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer11)\n",
        "layer12 = BatchNormalization()(layer12)\n",
        "layer12 = Activation('relu')(layer12)\n",
        "\n",
        "layer13 = Conv2D(512, (3,3), padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer12)\n",
        "layer13 = BatchNormalization()(layer13)\n",
        "layer13 = Activation('relu')(layer13)\n",
        "\n",
        "layer14 = Conv2D(512, (3,3), padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer13)\n",
        "layer14 = BatchNormalization()(layer14)\n",
        "layer14 = Activation('relu')(layer14)\n",
        "\n",
        "layer15 = concatenate([skip_connection_3, layer14)\n",
        "layer15 = BatchNormalization()(layer15)\n",
        "layer15 = Activation('relu')(layer15)\n",
        "layer15 = MaxPooling2D(pool_size=(2, 2))(layer15)\n",
        "\n",
        "\n",
        "#Layer 16\n",
        "layer16 = Conv2D(num_classes, (1,1), padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(1e-4))(layer15)\n",
        "layer16 = GlobalAveragePooling2D()(layer16)\n",
        "\n",
        "#Output Layer\n",
        "output = Activation('softmax')(layer16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4GP57feW7tI0",
        "colab_type": "code",
        "outputId": "c5a34187-188c-4042-9d62-ce2b57ea7656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2057
        }
      },
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 128)  36992       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 128)  147584      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 160)  0           activation_1[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 160)  640         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 160)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 160)  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 256)  368896      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 416)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 416)  1664        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 416)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 416)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1917440     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 512)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 512)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 928)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 928)  3712        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 928)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 928)    0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 200)    185800      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 11,822,920\n",
            "Trainable params: 11,812,680\n",
            "Non-trainable params: 10,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FEcnQ_Ev5L6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              #optimizer= RMSprop(epsilon=1e-08),\n",
        "              optimizer= Adam(lr= 0.0001, epsilon=1e-08),\n",
        "              #optimizer = SGD(momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "26Sr3tge564_",
        "colab_type": "code",
        "outputId": "5bce5155-f0d3-4ff9-f1e0-4d18a180f968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2553
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit the Model\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch= num_train // batch_size,\n",
        "                    validation_steps= num_validation // batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose=1, callbacks=[lr_reducer, checkpointer]\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/36\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 5.6243 - acc: 0.0484 - val_loss: 5.0938 - val_acc: 0.0997\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.09966, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 2/36\n",
            "781/781 [==============================] - 1183s 2s/step - loss: 5.0986 - acc: 0.1003 - val_loss: 4.7026 - val_acc: 0.1404\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.09966 to 0.14040, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 3/36\n",
            "781/781 [==============================] - 1181s 2s/step - loss: 4.7747 - acc: 0.1399 - val_loss: 4.3459 - val_acc: 0.1930\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.14040 to 0.19297, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 4/36\n",
            "781/781 [==============================] - 1181s 2s/step - loss: 4.5230 - acc: 0.1738 - val_loss: 4.2982 - val_acc: 0.1996\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.19297 to 0.19955, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 5/36\n",
            "781/781 [==============================] - 1177s 2s/step - loss: 4.3135 - acc: 0.2036 - val_loss: 3.8930 - val_acc: 0.2629\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.19955 to 0.26286, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 6/36\n",
            "781/781 [==============================] - 1173s 2s/step - loss: 4.1333 - acc: 0.2282 - val_loss: 3.8172 - val_acc: 0.2748\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.26286 to 0.27482, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 7/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.9889 - acc: 0.2514 - val_loss: 3.7918 - val_acc: 0.2808\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.27482 to 0.28079, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 8/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.8592 - acc: 0.2709 - val_loss: 3.6323 - val_acc: 0.3013\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.28079 to 0.30126, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 9/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.7526 - acc: 0.2873 - val_loss: 3.4333 - val_acc: 0.3372\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.30126 to 0.33722, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 10/36\n",
            "781/781 [==============================] - 1172s 2s/step - loss: 3.6471 - acc: 0.3059 - val_loss: 3.2899 - val_acc: 0.3624\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.33722 to 0.36244, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 11/36\n",
            "781/781 [==============================] - 1172s 2s/step - loss: 3.5688 - acc: 0.3160 - val_loss: 3.3176 - val_acc: 0.3622\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.36244\n",
            "Epoch 12/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.4863 - acc: 0.3296 - val_loss: 3.2565 - val_acc: 0.3688\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.36244 to 0.36882, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 13/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.4239 - acc: 0.3426 - val_loss: 3.1146 - val_acc: 0.3972\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.36882 to 0.39718, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 14/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.3565 - acc: 0.3519 - val_loss: 3.1495 - val_acc: 0.3920\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.39718\n",
            "Epoch 15/36\n",
            "781/781 [==============================] - 1171s 1s/step - loss: 3.2991 - acc: 0.3647 - val_loss: 3.0897 - val_acc: 0.4041\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.39718 to 0.40407, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 16/36\n",
            "781/781 [==============================] - 1170s 1s/step - loss: 3.2455 - acc: 0.3719 - val_loss: 2.9755 - val_acc: 0.4224\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.40407 to 0.42241, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 17/36\n",
            "781/781 [==============================] - 1170s 1s/step - loss: 3.1864 - acc: 0.3807 - val_loss: 2.8771 - val_acc: 0.4363\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.42241 to 0.43628, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 18/36\n",
            "781/781 [==============================] - 1170s 1s/step - loss: 3.1381 - acc: 0.3923 - val_loss: 2.9225 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.43628 to 0.43639, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 19/36\n",
            "781/781 [==============================] - 1170s 1s/step - loss: 3.0978 - acc: 0.3972 - val_loss: 2.9510 - val_acc: 0.4271\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.43639\n",
            "Epoch 20/36\n",
            "781/781 [==============================] - 1170s 1s/step - loss: 3.0526 - acc: 0.4075 - val_loss: 2.8904 - val_acc: 0.4340\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.43639\n",
            "Epoch 21/36\n",
            "781/781 [==============================] - 1170s 1s/step - loss: 3.0110 - acc: 0.4144 - val_loss: 2.8589 - val_acc: 0.4437\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.43639 to 0.44368, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 22/36\n",
            "781/781 [==============================] - 1169s 1s/step - loss: 2.9684 - acc: 0.4235 - val_loss: 2.8904 - val_acc: 0.4381\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.44368\n",
            "Epoch 23/36\n",
            "781/781 [==============================] - 1169s 1s/step - loss: 2.9260 - acc: 0.4292 - val_loss: 2.8020 - val_acc: 0.4568\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.44368 to 0.45685, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 24/36\n",
            "781/781 [==============================] - 1182s 2s/step - loss: 2.8891 - acc: 0.4366 - val_loss: 2.7165 - val_acc: 0.4713\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.45685 to 0.47133, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 25/36\n",
            "781/781 [==============================] - 1184s 2s/step - loss: 2.8535 - acc: 0.4428 - val_loss: 2.8282 - val_acc: 0.4462\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.47133\n",
            "Epoch 26/36\n",
            "781/781 [==============================] - 1183s 2s/step - loss: 2.8305 - acc: 0.4471 - val_loss: 2.7553 - val_acc: 0.4684\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.47133\n",
            "Epoch 27/36\n",
            "781/781 [==============================] - 1183s 2s/step - loss: 2.7981 - acc: 0.4538 - val_loss: 2.7370 - val_acc: 0.4715\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.47133 to 0.47154, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 28/36\n",
            "781/781 [==============================] - 1186s 2s/step - loss: 2.7630 - acc: 0.4590 - val_loss: 2.6784 - val_acc: 0.4801\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.47154 to 0.48015, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 29/36\n",
            "781/781 [==============================] - 1184s 2s/step - loss: 2.7342 - acc: 0.4647 - val_loss: 2.5377 - val_acc: 0.5021\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.48015 to 0.50213, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 30/36\n",
            "781/781 [==============================] - 1184s 2s/step - loss: 2.7009 - acc: 0.4722 - val_loss: 2.5754 - val_acc: 0.4950\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.50213\n",
            "Epoch 31/36\n",
            "781/781 [==============================] - 1184s 2s/step - loss: 2.6750 - acc: 0.4764 - val_loss: 2.6310 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.50213\n",
            "Epoch 32/36\n",
            "781/781 [==============================] - 1183s 2s/step - loss: 2.6478 - acc: 0.4818 - val_loss: 2.6284 - val_acc: 0.4866\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.50213\n",
            "Epoch 33/36\n",
            "781/781 [==============================] - 1181s 2s/step - loss: 2.6268 - acc: 0.4871 - val_loss: 2.7357 - val_acc: 0.4801\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.50213\n",
            "Epoch 34/36\n",
            "781/781 [==============================] - 1179s 2s/step - loss: 2.6034 - acc: 0.4892 - val_loss: 2.5798 - val_acc: 0.5016\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.50213\n",
            "Epoch 35/36\n",
            "781/781 [==============================] - 1172s 2s/step - loss: 2.4957 - acc: 0.5130 - val_loss: 2.4657 - val_acc: 0.5253\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.50213 to 0.52532, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n",
            "Epoch 36/36\n",
            "781/781 [==============================] - 1176s 2s/step - loss: 2.4566 - acc: 0.5217 - val_loss: 2.4199 - val_acc: 0.5380\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.52532 to 0.53799, saving model to /content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c139fdb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "5N-4QGG3rxby",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 12 hours of running and saving the model, I shall run the new model from here after skipping the above part. "
      ]
    },
    {
      "metadata": {
        "id": "ZvtAK5QCYYPn",
        "colab_type": "code",
        "outputId": "f4521bf2-ba35-4739-d68d-36d4b91c1bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 12 hours\n",
        "from keras.models import load_model\n",
        "new_model = load_model(\"/content/drive/My Drive/Colab Notebooks/top_acc_weights.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aR-KcYZdmf3P",
        "colab_type": "code",
        "outputId": "be8a1391-f115-410c-e3a3-00e070fe5569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2363
        }
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "checkpointer_new = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "new_model.fit_generator(train_generator,\n",
        "                        epochs=epochs,\n",
        "                        steps_per_epoch= num_train // batch_size,\n",
        "                        validation_steps= num_validation // batch_size,\n",
        "                        validation_data=validation_generator,\n",
        "                        verbose=1, callbacks=[lr_reducer, checkpointer_new]\n",
        "                       )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/36\n",
            "781/781 [==============================] - 1253s 2s/step - loss: 2.4292 - acc: 0.5250 - val_loss: 2.4123 - val_acc: 0.5427\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.54267, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 2/36\n",
            "781/781 [==============================] - 1240s 2s/step - loss: 2.4115 - acc: 0.5306 - val_loss: 2.4135 - val_acc: 0.5383\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.54267\n",
            "Epoch 3/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.3847 - acc: 0.5341 - val_loss: 2.4046 - val_acc: 0.5343\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.54267\n",
            "Epoch 4/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 2.3610 - acc: 0.5407 - val_loss: 2.4551 - val_acc: 0.5365\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.54267\n",
            "Epoch 5/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 2.3444 - acc: 0.5422 - val_loss: 2.3679 - val_acc: 0.5469\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.54267 to 0.54690, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 6/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 2.3264 - acc: 0.5448 - val_loss: 2.3332 - val_acc: 0.5515\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.54690 to 0.55146, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 7/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.3103 - acc: 0.5497 - val_loss: 2.3510 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.55146\n",
            "Epoch 8/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.2879 - acc: 0.5539 - val_loss: 2.4285 - val_acc: 0.5433\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.55146\n",
            "Epoch 9/36\n",
            "781/781 [==============================] - 1241s 2s/step - loss: 2.2683 - acc: 0.5586 - val_loss: 2.4056 - val_acc: 0.5355\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.55146\n",
            "Epoch 10/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 2.2490 - acc: 0.5628 - val_loss: 2.4101 - val_acc: 0.5398\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.55146\n",
            "Epoch 11/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 2.2330 - acc: 0.5645 - val_loss: 2.3863 - val_acc: 0.5434\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.55146\n",
            "Epoch 12/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.1434 - acc: 0.5840 - val_loss: 2.2975 - val_acc: 0.5633\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.55146 to 0.56331, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 13/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.1228 - acc: 0.5903 - val_loss: 2.2543 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.56331 to 0.56665, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 14/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.1030 - acc: 0.5934 - val_loss: 2.2461 - val_acc: 0.5772\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.56665 to 0.57719, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 15/36\n",
            "781/781 [==============================] - 1236s 2s/step - loss: 2.0860 - acc: 0.5961 - val_loss: 2.2627 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.57719\n",
            "Epoch 16/36\n",
            "781/781 [==============================] - 1236s 2s/step - loss: 2.0672 - acc: 0.5996 - val_loss: 2.3057 - val_acc: 0.5707\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.57719\n",
            "Epoch 17/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.0414 - acc: 0.6055 - val_loss: 2.2248 - val_acc: 0.5802\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.57719 to 0.58023, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 18/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.0347 - acc: 0.6063 - val_loss: 2.2518 - val_acc: 0.5737\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.58023\n",
            "Epoch 19/36\n",
            "781/781 [==============================] - 1237s 2s/step - loss: 2.0290 - acc: 0.6090 - val_loss: 2.2654 - val_acc: 0.5709\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.58023\n",
            "Epoch 20/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 2.0043 - acc: 0.6124 - val_loss: 2.2790 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.58023\n",
            "Epoch 21/36\n",
            "781/781 [==============================] - 1236s 2s/step - loss: 1.9907 - acc: 0.6175 - val_loss: 2.2821 - val_acc: 0.5712\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.58023\n",
            "Epoch 22/36\n",
            "781/781 [==============================] - 1236s 2s/step - loss: 1.9851 - acc: 0.6181 - val_loss: 2.2545 - val_acc: 0.5708\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.58023\n",
            "Epoch 23/36\n",
            "781/781 [==============================] - 1235s 2s/step - loss: 1.9055 - acc: 0.6360 - val_loss: 2.1831 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.58023 to 0.59096, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 24/36\n",
            "781/781 [==============================] - 1236s 2s/step - loss: 1.8796 - acc: 0.6420 - val_loss: 2.2058 - val_acc: 0.5852\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.59096\n",
            "Epoch 25/36\n",
            "781/781 [==============================] - 1238s 2s/step - loss: 1.8643 - acc: 0.6453 - val_loss: 2.1788 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.59096 to 0.59167, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 26/36\n",
            "781/781 [==============================] - 1242s 2s/step - loss: 1.8655 - acc: 0.6447 - val_loss: 2.2403 - val_acc: 0.5827\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.59167\n",
            "Epoch 27/36\n",
            "781/781 [==============================] - 1242s 2s/step - loss: 1.8481 - acc: 0.6477 - val_loss: 2.2036 - val_acc: 0.5866\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.59167\n",
            "Epoch 28/36\n",
            "781/781 [==============================] - 1243s 2s/step - loss: 1.8311 - acc: 0.6517 - val_loss: 2.2051 - val_acc: 0.5879\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.59167\n",
            "Epoch 29/36\n",
            "781/781 [==============================] - 1242s 2s/step - loss: 1.8231 - acc: 0.6520 - val_loss: 2.2063 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.59167\n",
            "Epoch 30/36\n",
            "781/781 [==============================] - 1242s 2s/step - loss: 1.8006 - acc: 0.6594 - val_loss: 2.1703 - val_acc: 0.5920\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.59167 to 0.59198, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 31/36\n",
            "781/781 [==============================] - 1241s 2s/step - loss: 1.7896 - acc: 0.6616 - val_loss: 2.2219 - val_acc: 0.5952\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.59198 to 0.59522, saving model to /content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\n",
            "Epoch 32/36\n",
            "781/781 [==============================] - 1241s 2s/step - loss: 1.7806 - acc: 0.6634 - val_loss: 2.2488 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.59522\n",
            "Epoch 33/36\n",
            "781/781 [==============================] - 1242s 2s/step - loss: 1.7663 - acc: 0.6656 - val_loss: 2.2680 - val_acc: 0.5780\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.59522\n",
            "Epoch 34/36\n",
            "781/781 [==============================] - 1242s 2s/step - loss: 1.7558 - acc: 0.6686 - val_loss: 2.2180 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.59522\n",
            "Epoch 35/36\n",
            "763/781 [============================>.] - ETA: 27s - loss: 1.7643 - acc: 0.6661"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUh42hHxCqyH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 24 hours of running and saving the model, I shall run the model from here after skipping the above parts. "
      ]
    },
    {
      "metadata": {
        "id": "_6FqwE2UHS2r",
        "colab_type": "code",
        "outputId": "3c0de27c-e75d-4427-9d86-d68fe2e42ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 24 hours\n",
        "from keras.models import load_model\n",
        "new_model = load_model(\"/content/drive/My Drive/Colab Notebooks/new_top_acc_weights.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o7D5DMcFC1jw",
        "colab_type": "code",
        "outputId": "c6eaaac0-aaf6-411d-b483-b8cef09210f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2074
        }
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "checkpointer_new = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "new_model.fit_generator(train_generator,\n",
        "                        epochs=30,\n",
        "                        steps_per_epoch= num_train // batch_size,\n",
        "                        validation_steps= num_validation // batch_size,\n",
        "                        validation_data=validation_generator,\n",
        "                        verbose=1, callbacks=[lr_reducer, checkpointer_new]\n",
        "                       )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "781/781 [==============================] - 1213s 2s/step - loss: 1.7795 - acc: 0.6641 - val_loss: 2.2226 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.58223, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 2/30\n",
            "781/781 [==============================] - 1199s 2s/step - loss: 1.7690 - acc: 0.6669 - val_loss: 2.2461 - val_acc: 0.5872\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.58223 to 0.58722, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 3/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.7522 - acc: 0.6704 - val_loss: 2.2255 - val_acc: 0.5860\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.58722\n",
            "Epoch 4/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.7394 - acc: 0.6740 - val_loss: 2.2715 - val_acc: 0.5836\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.58722\n",
            "Epoch 5/30\n",
            "781/781 [==============================] - 1195s 2s/step - loss: 1.7318 - acc: 0.6746 - val_loss: 2.2458 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.58722\n",
            "Epoch 6/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.7180 - acc: 0.6776 - val_loss: 2.2122 - val_acc: 0.5889\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.58722 to 0.58894, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 7/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.7134 - acc: 0.6800 - val_loss: 2.2284 - val_acc: 0.5814\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.58894\n",
            "Epoch 8/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.6977 - acc: 0.6819 - val_loss: 2.2762 - val_acc: 0.5743\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.58894\n",
            "Epoch 9/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.6865 - acc: 0.6863 - val_loss: 2.2487 - val_acc: 0.5756\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.58894\n",
            "Epoch 10/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.6764 - acc: 0.6872 - val_loss: 2.2933 - val_acc: 0.5758\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.58894\n",
            "Epoch 11/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.6676 - acc: 0.6902 - val_loss: 2.2499 - val_acc: 0.5733\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.58894\n",
            "Epoch 12/30\n",
            "781/781 [==============================] - 1200s 2s/step - loss: 1.6395 - acc: 0.6967 - val_loss: 2.2042 - val_acc: 0.5939\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.58894 to 0.59390, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 13/30\n",
            "781/781 [==============================] - 1195s 2s/step - loss: 1.6247 - acc: 0.7002 - val_loss: 2.1760 - val_acc: 0.5943\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.59390 to 0.59431, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 14/30\n",
            "781/781 [==============================] - 1195s 2s/step - loss: 1.6110 - acc: 0.7039 - val_loss: 2.1832 - val_acc: 0.5965\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.59431 to 0.59654, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 15/30\n",
            "781/781 [==============================] - 1195s 2s/step - loss: 1.6014 - acc: 0.7047 - val_loss: 2.1652 - val_acc: 0.5958\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.59654\n",
            "Epoch 16/30\n",
            "781/781 [==============================] - 1197s 2s/step - loss: 1.5912 - acc: 0.7072 - val_loss: 2.2218 - val_acc: 0.5959\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59654\n",
            "Epoch 17/30\n",
            "781/781 [==============================] - 1197s 2s/step - loss: 1.5706 - acc: 0.7126 - val_loss: 2.1935 - val_acc: 0.5926\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59654\n",
            "Epoch 18/30\n",
            "781/781 [==============================] - 1199s 2s/step - loss: 1.5705 - acc: 0.7122 - val_loss: 2.2314 - val_acc: 0.5873\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59654\n",
            "Epoch 19/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.5695 - acc: 0.7114 - val_loss: 2.2111 - val_acc: 0.5940\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59654\n",
            "Epoch 20/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.5499 - acc: 0.7157 - val_loss: 2.2031 - val_acc: 0.5918\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.59654\n",
            "Epoch 21/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.5166 - acc: 0.7270 - val_loss: 2.1675 - val_acc: 0.6029\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.59654 to 0.60292, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 22/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.5063 - acc: 0.7294 - val_loss: 2.1565 - val_acc: 0.5980\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.60292\n",
            "Epoch 23/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.5100 - acc: 0.7277 - val_loss: 2.1593 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.60292\n",
            "Epoch 24/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.4949 - acc: 0.7302 - val_loss: 2.1715 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.60292\n",
            "Epoch 25/30\n",
            "781/781 [==============================] - 1197s 2s/step - loss: 1.4889 - acc: 0.7327 - val_loss: 2.1717 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.60292\n",
            "Epoch 26/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.4908 - acc: 0.7333 - val_loss: 2.2076 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.60292\n",
            "Epoch 27/30\n",
            "781/781 [==============================] - 1197s 2s/step - loss: 1.4817 - acc: 0.7337 - val_loss: 2.1801 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.60292\n",
            "Epoch 28/30\n",
            "781/781 [==============================] - 1199s 2s/step - loss: 1.4547 - acc: 0.7416 - val_loss: 2.1435 - val_acc: 0.6047\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.60292 to 0.60474, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n",
            "Epoch 29/30\n",
            "781/781 [==============================] - 1198s 2s/step - loss: 1.4450 - acc: 0.7439 - val_loss: 2.1621 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.60474\n",
            "Epoch 30/30\n",
            "781/781 [==============================] - 1196s 2s/step - loss: 1.4280 - acc: 0.7493 - val_loss: 2.1243 - val_acc: 0.6076\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.60474 to 0.60758, saving model to /content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f420bb4c6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0vBL5LvwvQe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After 34 hours with a total of 100 epochs we get a validation accuracy of 60.76% which is currently saturated as it reached here from accuracy of 59.53% of last run after 30 epochs."
      ]
    },
    {
      "metadata": {
        "id": "kjFT704aO1dU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Run on Oversampling the Misclassified Training Data"
      ]
    },
    {
      "metadata": {
        "id": "cNkhKuVsfI5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Before further running the model, we shall now divide the training set into two different sets of good and bad images, which represents the images correctly classified and incorrectly classified respectively. And further train our model on it for improving val accuracy."
      ]
    },
    {
      "metadata": {
        "id": "S2Nfcs6QDB_O",
        "colab_type": "code",
        "outputId": "d728dd6f-0801-49c1-c478-b835148ca375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 34 hours\n",
        "from keras.models import load_model\n",
        "final_model = load_model(\"/content/drive/My Drive/Colab Notebooks/final_top_acc_weights.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VxJgKbJnfHJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create directories and foldrs for good and bad images\n",
        "from os import makedirs\n",
        "from os.path import join\n",
        "\n",
        "for _class in validation_generator.class_indices.keys():\n",
        "  makedirs(join('good_images',_class))\n",
        "  makedirs(join('bad_images', _class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ojtceki9fu8o",
        "colab_type": "code",
        "outputId": "543dc082-4ce2-4cbf-a336-82063d1a64fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Prediction on training dataset\n",
        "pred_train=final_model.predict_generator(train_generator, steps= np.ceil(num_train/batch_size), verbose=1)\n",
        "pred_train_class_indices=np.argmax(pred_train,axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 627s 802ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CrJCBmiCfud9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Label the training dataset\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in pred_train_class_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hz91XG2CtVF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copy the respective images to good and bad images folders according to their classification\n",
        "import shutil\n",
        "k, num_good, num_bad = 0, 0, 0\n",
        "for i in range(200):\n",
        "  for j in range(500):\n",
        "    if pred_train_class_indices[k+j] == i and k+j != 100000:\n",
        "      num_good += 1\n",
        "      shutil.copy2('tiny-imagenet-200/train/'+labels[i]+'/images/'+labels[i]+'_'+str(j)+'.JPEG', 'good_images/'+labels[i])\n",
        "    else:\n",
        "      num_bad += 1\n",
        "      shutil.copy2('tiny-imagenet-200/train/'+labels[i]+'/images/'+labels[i]+'_'+str(j)+'.JPEG', 'bad_images/'+labels[i])\n",
        "      \n",
        "  k += 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kg0vZl9af9wX",
        "colab_type": "code",
        "outputId": "c59f1b62-82cf-4a4b-b86c-856f45d2a352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Creating good and bad training image dataset\n",
        "good_train = train_datagen.flow_from_directory( r'./good_images/', \n",
        "                                                    target_size=(img_width, img_height), \n",
        "                                                    batch_size=batch_size, \n",
        "                                                    class_mode='categorical', \n",
        "                                                    shuffle=True, \n",
        "                                                    seed=101)\n",
        "bad_train = train_datagen.flow_from_directory( r'./bad_images/', \n",
        "                                                    target_size=(img_width, img_height), \n",
        "                                                    batch_size=batch_size, \n",
        "                                                    class_mode='categorical', \n",
        "                                                    shuffle=True, \n",
        "                                                    seed=101)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 72831 images belonging to 200 classes.\n",
            "Found 27169 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yFSzIXfLgOP4",
        "colab_type": "code",
        "outputId": "3b5aa25e-a2ce-4b7e-90bb-a0d5a4363f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7157
        }
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "checkpointer_extended = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/extended_model_weights.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"\\n Epoch for 1 good : 9 bad training ==> \", i+1)\n",
        "  final_model.fit_generator(good_train,\n",
        "                            epochs=1,\n",
        "                            steps_per_epoch= np.ceil(num_good/batch_size),\n",
        "                            validation_steps= np.ceil(num_validation/batch_size),\n",
        "                            validation_data=validation_generator,\n",
        "                            verbose=1, callbacks=[lr_reducer, checkpointer_extended]\n",
        "                            )\n",
        "  \n",
        "  final_model.fit_generator(bad_train,\n",
        "                            epochs=9,\n",
        "                            steps_per_epoch= np.ceil(num_bad/batch_size),\n",
        "                            validation_steps= np.ceil(num_validation/batch_size),\n",
        "                            validation_data=validation_generator,\n",
        "                            verbose=1, callbacks=[lr_reducer, checkpointer_extended]\n",
        "                            )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch for 1 good : 9 bad training ==>  1\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 911s 2s/step - loss: 1.4871 - acc: 0.7303 - val_loss: 2.1628 - val_acc: 0.6062\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.60620, saving model to /content/drive/My Drive/Colab Notebooks/extended_model_weights.hdf5\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.6545 - acc: 0.6866 - val_loss: 2.1820 - val_acc: 0.6049\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.60620\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.6144 - acc: 0.6980 - val_loss: 2.1887 - val_acc: 0.5985\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.60620\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 357s 2s/step - loss: 1.5911 - acc: 0.7012 - val_loss: 2.1844 - val_acc: 0.5987\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.60620\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.5603 - acc: 0.7117 - val_loss: 2.1847 - val_acc: 0.6008\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.60620\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.5610 - acc: 0.7115 - val_loss: 2.2061 - val_acc: 0.5997\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.60620\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.5420 - acc: 0.7213 - val_loss: 2.2110 - val_acc: 0.5954\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.60620\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.5192 - acc: 0.7234 - val_loss: 2.1731 - val_acc: 0.5989\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.60620\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.5073 - acc: 0.7261 - val_loss: 2.1943 - val_acc: 0.5994\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.60620\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4916 - acc: 0.7312 - val_loss: 2.1759 - val_acc: 0.6047\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.60620\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  2\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 902s 2s/step - loss: 1.5201 - acc: 0.7209 - val_loss: 2.1494 - val_acc: 0.6058\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.60620\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.5259 - acc: 0.7256 - val_loss: 2.1582 - val_acc: 0.6062\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.60620\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.4895 - acc: 0.7325 - val_loss: 2.1846 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.60620\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4769 - acc: 0.7349 - val_loss: 2.1596 - val_acc: 0.6043\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.60620\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4827 - acc: 0.7321 - val_loss: 2.1831 - val_acc: 0.6004\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.60620\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.4687 - acc: 0.7378 - val_loss: 2.1932 - val_acc: 0.5960\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.60620\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.4642 - acc: 0.7388 - val_loss: 2.1914 - val_acc: 0.6012\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.60620\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.4563 - acc: 0.7417 - val_loss: 2.2009 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.60620\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.4429 - acc: 0.7424 - val_loss: 2.1908 - val_acc: 0.5961\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.60620\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.4347 - acc: 0.7463 - val_loss: 2.1928 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.60620\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  3\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 899s 2s/step - loss: 1.5241 - acc: 0.7201 - val_loss: 2.1426 - val_acc: 0.6102\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.60620 to 0.61020, saving model to /content/drive/My Drive/Colab Notebooks/extended_model_weights.hdf5\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.4693 - acc: 0.7387 - val_loss: 2.1469 - val_acc: 0.6065\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61020\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4515 - acc: 0.7420 - val_loss: 2.1763 - val_acc: 0.6055\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61020\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4264 - acc: 0.7479 - val_loss: 2.1611 - val_acc: 0.6036\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61020\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.4255 - acc: 0.7477 - val_loss: 2.1846 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61020\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4238 - acc: 0.7492 - val_loss: 2.1814 - val_acc: 0.6027\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61020\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.4186 - acc: 0.7490 - val_loss: 2.1975 - val_acc: 0.5989\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61020\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 363s 2s/step - loss: 1.4046 - acc: 0.7541 - val_loss: 2.1840 - val_acc: 0.6031\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61020\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 363s 2s/step - loss: 1.3945 - acc: 0.7612 - val_loss: 2.1808 - val_acc: 0.6005\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61020\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3857 - acc: 0.7619 - val_loss: 2.1796 - val_acc: 0.6012\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61020\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  4\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 900s 2s/step - loss: 1.5225 - acc: 0.7205 - val_loss: 2.1409 - val_acc: 0.6113\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.61020 to 0.61130, saving model to /content/drive/My Drive/Colab Notebooks/extended_model_weights.hdf5\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.4239 - acc: 0.7466 - val_loss: 2.1470 - val_acc: 0.6073\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.4131 - acc: 0.7535 - val_loss: 2.1732 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3931 - acc: 0.7572 - val_loss: 2.1705 - val_acc: 0.6050\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3948 - acc: 0.7602 - val_loss: 2.1756 - val_acc: 0.5994\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.4008 - acc: 0.7569 - val_loss: 2.1727 - val_acc: 0.6012\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3936 - acc: 0.7556 - val_loss: 2.1824 - val_acc: 0.5989\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3753 - acc: 0.7600 - val_loss: 2.1884 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3784 - acc: 0.7615 - val_loss: 2.1800 - val_acc: 0.6019\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3792 - acc: 0.7618 - val_loss: 2.1916 - val_acc: 0.5988\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  5\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 903s 2s/step - loss: 1.5395 - acc: 0.7156 - val_loss: 2.1425 - val_acc: 0.6095\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.4102 - acc: 0.7507 - val_loss: 2.1424 - val_acc: 0.6094\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3790 - acc: 0.7637 - val_loss: 2.1522 - val_acc: 0.6043\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3745 - acc: 0.7649 - val_loss: 2.1615 - val_acc: 0.6033\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3710 - acc: 0.7654 - val_loss: 2.1688 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3784 - acc: 0.7602 - val_loss: 2.1778 - val_acc: 0.6004\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3614 - acc: 0.7666 - val_loss: 2.1810 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3646 - acc: 0.7682 - val_loss: 2.1762 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3671 - acc: 0.7655 - val_loss: 2.1813 - val_acc: 0.6005\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3482 - acc: 0.7701 - val_loss: 2.1752 - val_acc: 0.6004\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  6\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 899s 2s/step - loss: 1.5358 - acc: 0.7167 - val_loss: 2.1503 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3869 - acc: 0.7601 - val_loss: 2.1444 - val_acc: 0.6085\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3697 - acc: 0.7643 - val_loss: 2.1534 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3523 - acc: 0.7721 - val_loss: 2.1629 - val_acc: 0.6036\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3666 - acc: 0.7643 - val_loss: 2.1703 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3463 - acc: 0.7702 - val_loss: 2.1737 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3453 - acc: 0.7709 - val_loss: 2.1730 - val_acc: 0.6005\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3588 - acc: 0.7683 - val_loss: 2.1750 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3265 - acc: 0.7763 - val_loss: 2.1797 - val_acc: 0.6017\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3510 - acc: 0.7680 - val_loss: 2.1798 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  7\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 902s 2s/step - loss: 1.5365 - acc: 0.7171 - val_loss: 2.1526 - val_acc: 0.6109\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3758 - acc: 0.7618 - val_loss: 2.1464 - val_acc: 0.6091\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3604 - acc: 0.7676 - val_loss: 2.1540 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3460 - acc: 0.7687 - val_loss: 2.1618 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3479 - acc: 0.7718 - val_loss: 2.1641 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3462 - acc: 0.7730 - val_loss: 2.1678 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3429 - acc: 0.7709 - val_loss: 2.1699 - val_acc: 0.6033\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3234 - acc: 0.7772 - val_loss: 2.1728 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3433 - acc: 0.7715 - val_loss: 2.1755 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3383 - acc: 0.7713 - val_loss: 2.1770 - val_acc: 0.6031\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  8\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 900s 2s/step - loss: 1.5331 - acc: 0.7157 - val_loss: 2.1536 - val_acc: 0.6073\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3559 - acc: 0.7665 - val_loss: 2.1471 - val_acc: 0.6070\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3410 - acc: 0.7700 - val_loss: 2.1509 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3489 - acc: 0.7712 - val_loss: 2.1594 - val_acc: 0.6043\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3468 - acc: 0.7703 - val_loss: 2.1632 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3421 - acc: 0.7703 - val_loss: 2.1658 - val_acc: 0.6033\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3515 - acc: 0.7721 - val_loss: 2.1705 - val_acc: 0.6014\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3441 - acc: 0.7710 - val_loss: 2.1712 - val_acc: 0.6020\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3329 - acc: 0.7739 - val_loss: 2.1725 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3309 - acc: 0.7731 - val_loss: 2.1763 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  9\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 899s 2s/step - loss: 1.5448 - acc: 0.7130 - val_loss: 2.1544 - val_acc: 0.6066\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3529 - acc: 0.7668 - val_loss: 2.1471 - val_acc: 0.6068\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 358s 2s/step - loss: 1.3615 - acc: 0.7658 - val_loss: 2.1532 - val_acc: 0.6057\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3513 - acc: 0.7669 - val_loss: 2.1585 - val_acc: 0.6042\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3310 - acc: 0.7772 - val_loss: 2.1645 - val_acc: 0.6036\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3494 - acc: 0.7661 - val_loss: 2.1687 - val_acc: 0.6010\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 359s 2s/step - loss: 1.3253 - acc: 0.7764 - val_loss: 2.1701 - val_acc: 0.6013\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 360s 2s/step - loss: 1.3281 - acc: 0.7767 - val_loss: 2.1707 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3299 - acc: 0.7772 - val_loss: 2.1724 - val_acc: 0.6013\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3336 - acc: 0.7715 - val_loss: 2.1771 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n",
            "\n",
            " Epoch for 1 good : 9 bad training ==>  10\n",
            "Epoch 1/1\n",
            "569/569 [==============================] - 902s 2s/step - loss: 1.5404 - acc: 0.7139 - val_loss: 2.1525 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 1/9\n",
            "213/213 [==============================] - 363s 2s/step - loss: 1.3419 - acc: 0.7721 - val_loss: 2.1513 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61130\n",
            "Epoch 2/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3396 - acc: 0.7749 - val_loss: 2.1570 - val_acc: 0.6053\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61130\n",
            "Epoch 3/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3434 - acc: 0.7710 - val_loss: 2.1600 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61130\n",
            "Epoch 4/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3280 - acc: 0.7765 - val_loss: 2.1650 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61130\n",
            "Epoch 5/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3319 - acc: 0.7742 - val_loss: 2.1679 - val_acc: 0.6029\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61130\n",
            "Epoch 6/9\n",
            "213/213 [==============================] - 361s 2s/step - loss: 1.3295 - acc: 0.7734 - val_loss: 2.1716 - val_acc: 0.6002\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61130\n",
            "Epoch 7/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3409 - acc: 0.7709 - val_loss: 2.1730 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61130\n",
            "Epoch 8/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3276 - acc: 0.7780 - val_loss: 2.1765 - val_acc: 0.5995\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61130\n",
            "Epoch 9/9\n",
            "213/213 [==============================] - 362s 2s/step - loss: 1.3250 - acc: 0.7765 - val_loss: 2.1752 - val_acc: 0.5998\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h34gwTEYxW-Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The process didn't help that much to improve val accuracy as model accuracy had completely saturated."
      ]
    },
    {
      "metadata": {
        "id": "sMdyCiAmPYjS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Run on Weighting the Classes with Low Precision\n",
        "\n",
        "We use it so that, if you miss-classify classA the loss will be n times more than miss-classifying classB and so on.."
      ]
    },
    {
      "metadata": {
        "id": "co7wMpk4TH-z",
        "colab_type": "code",
        "outputId": "bcbd4b46-657d-4795-8832-9276649578f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# load the model after 46 hours\n",
        "from keras.models import load_model\n",
        "extended_model = load_model(\"/content/drive/My Drive/Colab Notebooks/extended_model_weights.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Q2iNyWR3vxR",
        "colab_type": "code",
        "outputId": "95c03752-1f06-4ac8-9f2c-75b72506fd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "score= extended_model.evaluate_generator(validation_generator, steps= np.ceil(num_validation/batch_size), verbose=1)\n",
        "print(\"Validation Loss : \", score[0])\n",
        "print(\"Validation Accuracy:\", score[1]*100, \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 43s 540ms/step\n",
            "Validation Loss :  2.140896961593628\n",
            "Validation Accuracy: 61.129999999999995 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G40AoKzoxrhp",
        "colab_type": "code",
        "outputId": "abaa3e54-d2de-4f7f-f668-f617499a947f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "pred=extended_model.predict_generator(validation_generator, steps= np.ceil(num_validation/batch_size), verbose=1)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 43s 545ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wgEiuuEWzMpf",
        "colab_type": "code",
        "outputId": "50d7a946-8c39-4572-d701-39e3608fbfd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Predicted class indices of 1st 10 val images\n",
        "predicted_class_indices[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([107,  15,  83,  81, 168, 161, 147, 172, 145,  10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "GhCvS_rY5nSA",
        "colab_type": "code",
        "outputId": "834de17c-5500-4c09-d38f-291697352fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# True class indices of 1st 10 val images\n",
        "validation_generator.classes[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[107, 139, 140, 69, 69, 161, 147, 73, 145, 39]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "HfOyrlPyz-Wh",
        "colab_type": "code",
        "outputId": "22fd6b32-513e-47b3-e88b-d8654806b375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Predicted classes from their indices\n",
        "labels = (validation_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "predictions[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n03444034',\n",
              " 'n01944390',\n",
              " 'n02948072',\n",
              " 'n02917067',\n",
              " 'n04507155',\n",
              " 'n04399382',\n",
              " 'n04179913',\n",
              " 'n04560804',\n",
              " 'n04146614',\n",
              " 'n01784675']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "xufarZCvCFit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Validation class names from words.txt\n",
        "import os\n",
        "class_to_name = dict()\n",
        "file = open('tiny-imagenet-200/words.txt','r')\n",
        "data= file.readlines()\n",
        "for line in data:\n",
        "  words = line.strip('\\n').split('\\t')\n",
        "  class_to_name[words[0]] = words[1].split(',')[0]\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVFFGvbCs2FJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Asserting Validation Class names from words.txt\n",
        "validation_class_names={}\n",
        "for _class in validation_generator.class_indices.keys():\n",
        "  validation_class_names.update({_class : class_to_name[_class]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O68VICf7175I",
        "colab_type": "code",
        "outputId": "102e60bd-d90e-4b1f-d568-a988f2cf8fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3536
        }
      },
      "cell_type": "code",
      "source": [
        "# Classification Report of val classes\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(classification_report(validation_generator.classes, predicted_class_indices,\n",
        "                            #target_names=validation_generator.class_indices.keys(),\n",
        "                            target_names=validation_class_names.values(),\n",
        "                            digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                goldfish     0.7736    0.8200    0.7961        50\n",
            "European fire salamander     0.8913    0.8200    0.8542        50\n",
            "                bullfrog     0.6250    0.6000    0.6122        50\n",
            "             tailed frog     0.5652    0.5200    0.5417        50\n",
            "      American alligator     0.6042    0.5800    0.5918        50\n",
            "         boa constrictor     0.4681    0.4400    0.4536        50\n",
            "               trilobite     0.6923    0.9000    0.7826        50\n",
            "                scorpion     0.6429    0.5400    0.5870        50\n",
            "             black widow     0.7241    0.8400    0.7778        50\n",
            "               tarantula     0.6731    0.7000    0.6863        50\n",
            "               centipede     0.5962    0.6200    0.6078        50\n",
            "                   goose     0.7805    0.6400    0.7033        50\n",
            "                   koala     0.7885    0.8200    0.8039        50\n",
            "               jellyfish     0.6786    0.7600    0.7170        50\n",
            "             brain coral     0.6066    0.7400    0.6667        50\n",
            "                   snail     0.6250    0.5000    0.5556        50\n",
            "                    slug     0.5333    0.4800    0.5053        50\n",
            "                sea slug     0.7857    0.6600    0.7174        50\n",
            "        American lobster     0.6444    0.5800    0.6105        50\n",
            "           spiny lobster     0.7000    0.7000    0.7000        50\n",
            "             black stork     0.8000    0.8800    0.8381        50\n",
            "            king penguin     0.9250    0.7400    0.8222        50\n",
            "               albatross     0.7800    0.7800    0.7800        50\n",
            "                  dugong     0.8246    0.9400    0.8785        50\n",
            "               Chihuahua     0.4565    0.4200    0.4375        50\n",
            "       Yorkshire terrier     0.8000    0.8000    0.8000        50\n",
            "        golden retriever     0.5849    0.6200    0.6019        50\n",
            "      Labrador retriever     0.4035    0.4600    0.4299        50\n",
            "         German shepherd     0.5833    0.5600    0.5714        50\n",
            "         standard poodle     0.4474    0.3400    0.3864        50\n",
            "                   tabby     0.6410    0.5000    0.5618        50\n",
            "             Persian cat     0.7347    0.7200    0.7273        50\n",
            "            Egyptian cat     0.4762    0.4000    0.4348        50\n",
            "                  cougar     0.6304    0.5800    0.6042        50\n",
            "                    lion     0.7143    0.7000    0.7071        50\n",
            "              brown bear     0.6038    0.6400    0.6214        50\n",
            "                 ladybug     0.7963    0.8600    0.8269        50\n",
            "                     fly     0.7059    0.7200    0.7129        50\n",
            "                     bee     0.7547    0.8000    0.7767        50\n",
            "             grasshopper     0.5000    0.5800    0.5370        50\n",
            "           walking stick     0.5625    0.5400    0.5510        50\n",
            "               cockroach     0.5870    0.5400    0.5625        50\n",
            "                  mantis     0.6957    0.6400    0.6667        50\n",
            "               dragonfly     0.5600    0.5600    0.5600        50\n",
            "                 monarch     0.9362    0.8800    0.9072        50\n",
            "       sulphur butterfly     0.8776    0.8600    0.8687        50\n",
            "            sea cucumber     0.6087    0.5600    0.5833        50\n",
            "              guinea pig     0.6735    0.6600    0.6667        50\n",
            "                     hog     0.4250    0.3400    0.3778        50\n",
            "                      ox     0.5750    0.4600    0.5111        50\n",
            "                   bison     0.6545    0.7200    0.6857        50\n",
            "                 bighorn     0.7105    0.5400    0.6136        50\n",
            "                 gazelle     0.7636    0.8400    0.8000        50\n",
            "           Arabian camel     0.6939    0.6800    0.6869        50\n",
            "               orangutan     0.6909    0.7600    0.7238        50\n",
            "              chimpanzee     0.5846    0.7600    0.6609        50\n",
            "                  baboon     0.6275    0.6400    0.6337        50\n",
            "        African elephant     0.6727    0.7400    0.7048        50\n",
            "            lesser panda     0.9268    0.7600    0.8352        50\n",
            "                  abacus     0.5800    0.5800    0.5800        50\n",
            "           academic gown     0.7255    0.7400    0.7327        50\n",
            "                   altar     0.6200    0.6200    0.6200        50\n",
            "                   apron     0.3922    0.4000    0.3960        50\n",
            "                backpack     0.5800    0.5800    0.5800        50\n",
            "               bannister     0.3778    0.3400    0.3579        50\n",
            "              barbershop     0.4783    0.4400    0.4583        50\n",
            "                    barn     0.6875    0.6600    0.6735        50\n",
            "                  barrel     0.5278    0.3800    0.4419        50\n",
            "              basketball     0.7750    0.6200    0.6889        50\n",
            "                 bathtub     0.5192    0.5400    0.5294        50\n",
            "             beach wagon     0.4912    0.5600    0.5234        50\n",
            "                  beacon     0.7321    0.8200    0.7736        50\n",
            "                  beaker     0.6279    0.5400    0.5806        50\n",
            "             beer bottle     0.5094    0.5400    0.5243        50\n",
            "                  bikini     0.7045    0.6200    0.6596        50\n",
            "              binoculars     0.5000    0.5000    0.5000        50\n",
            "               birdhouse     0.6829    0.5600    0.6154        50\n",
            "                 bow tie     0.4103    0.3200    0.3596        50\n",
            "                   brass     0.6552    0.7600    0.7037        50\n",
            "                   broom     0.5278    0.3800    0.4419        50\n",
            "                  bucket     0.3556    0.3200    0.3368        50\n",
            "            bullet train     0.8182    0.9000    0.8571        50\n",
            "            butcher shop     0.7609    0.7000    0.7292        50\n",
            "                  candle     0.6000    0.4800    0.5333        50\n",
            "                  cannon     0.5952    0.5000    0.5435        50\n",
            "                cardigan     0.6042    0.5800    0.5918        50\n",
            "            cash machine     0.5000    0.5800    0.5370        50\n",
            "               CD player     0.5283    0.5600    0.5437        50\n",
            "                   chain     0.5610    0.4600    0.5055        50\n",
            "                   chest     0.5625    0.5400    0.5510        50\n",
            "      Christmas stocking     0.6111    0.6600    0.6346        50\n",
            "          cliff dwelling     0.7556    0.6800    0.7158        50\n",
            "       computer keyboard     0.6182    0.6800    0.6476        50\n",
            "           confectionery     0.6441    0.7600    0.6972        50\n",
            "             convertible     0.4490    0.4400    0.4444        50\n",
            "                   crane     0.6809    0.6400    0.6598        50\n",
            "                     dam     0.5217    0.4800    0.5000        50\n",
            "                    desk     0.4918    0.6000    0.5405        50\n",
            "            dining table     0.6792    0.7200    0.6990        50\n",
            "               drumstick     0.3279    0.4000    0.3604        50\n",
            "                dumbbell     0.3830    0.3600    0.3711        50\n",
            "                flagpole     0.6731    0.7000    0.6863        50\n",
            "                fountain     0.5882    0.6000    0.5941        50\n",
            "             freight car     0.7736    0.8200    0.7961        50\n",
            "              frying pan     0.4783    0.4400    0.4583        50\n",
            "                fur coat     0.5000    0.4400    0.4681        50\n",
            "                 gasmask     0.4386    0.5000    0.4673        50\n",
            "                 go-kart     0.7755    0.7600    0.7677        50\n",
            "                 gondola     0.7895    0.9000    0.8411        50\n",
            "               hourglass     0.6071    0.6800    0.6415        50\n",
            "                    iPod     0.5286    0.7400    0.6167        50\n",
            "              jinrikisha     0.6731    0.7000    0.6863        50\n",
            "                  kimono     0.5106    0.4800    0.4948        50\n",
            "               lampshade     0.5179    0.5800    0.5472        50\n",
            "              lawn mower     0.5870    0.5400    0.5625        50\n",
            "                lifeboat     0.8723    0.8200    0.8454        50\n",
            "               limousine     0.5714    0.4800    0.5217        50\n",
            "        magnetic compass     0.6154    0.6400    0.6275        50\n",
            "                 maypole     0.7308    0.7600    0.7451        50\n",
            "        military uniform     0.4878    0.4000    0.4396        50\n",
            "               miniskirt     0.4262    0.5200    0.4685        50\n",
            "              moving van     0.7778    0.7000    0.7368        50\n",
            "                    nail     0.4872    0.3800    0.4270        50\n",
            "              neck brace     0.4694    0.4600    0.4646        50\n",
            "                 obelisk     0.6964    0.7800    0.7358        50\n",
            "                    oboe     0.4889    0.4400    0.4632        50\n",
            "                   organ     0.6604    0.7000    0.6796        50\n",
            "           parking meter     0.5200    0.5200    0.5200        50\n",
            "               pay-phone     0.5088    0.5800    0.5421        50\n",
            "            picket fence     0.7551    0.7400    0.7475        50\n",
            "             pill bottle     0.5417    0.5200    0.5306        50\n",
            "                 plunger     0.3030    0.2000    0.2410        50\n",
            "                    pole     0.2955    0.2600    0.2766        50\n",
            "              police van     0.8298    0.7800    0.8041        50\n",
            "                  poncho     0.4925    0.6600    0.5641        50\n",
            "              pop bottle     0.3415    0.2800    0.3077        50\n",
            "          potter's wheel     0.4265    0.5800    0.4915        50\n",
            "              projectile     0.5946    0.4400    0.5057        50\n",
            "            punching bag     0.3393    0.3800    0.3585        50\n",
            "                    reel     0.5833    0.4200    0.4884        50\n",
            "            refrigerator     0.5962    0.6200    0.6078        50\n",
            "          remote control     0.5577    0.5800    0.5686        50\n",
            "           rocking chair     0.5714    0.5600    0.5657        50\n",
            "              rugby ball     0.8269    0.8600    0.8431        50\n",
            "                  sandal     0.5789    0.6600    0.6168        50\n",
            "              school bus     0.8033    0.9800    0.8829        50\n",
            "              scoreboard     0.7708    0.7400    0.7551        50\n",
            "          sewing machine     0.5200    0.5200    0.5200        50\n",
            "                 snorkel     0.6458    0.6200    0.6327        50\n",
            "                    sock     0.6154    0.6400    0.6275        50\n",
            "                sombrero     0.5849    0.6200    0.6019        50\n",
            "            space heater     0.3729    0.4400    0.4037        50\n",
            "              spider web     0.5000    0.7000    0.5833        50\n",
            "              sports car     0.5660    0.6000    0.5825        50\n",
            "       steel arch bridge     0.6458    0.6200    0.6327        50\n",
            "               stopwatch     0.5273    0.5800    0.5524        50\n",
            "              sunglasses     0.5217    0.4800    0.5000        50\n",
            "       suspension bridge     0.6078    0.6200    0.6139        50\n",
            "         swimming trunks     0.6111    0.4400    0.5116        50\n",
            "                 syringe     0.3143    0.2200    0.2588        50\n",
            "                  teapot     0.3733    0.5600    0.4480        50\n",
            "                   teddy     0.6957    0.6400    0.6667        50\n",
            "                  thatch     0.7174    0.6600    0.6875        50\n",
            "                   torch     0.6304    0.5800    0.6042        50\n",
            "                 tractor     0.5965    0.6800    0.6355        50\n",
            "          triumphal arch     0.8400    0.8400    0.8400        50\n",
            "              trolleybus     0.8958    0.8600    0.8776        50\n",
            "               turnstile     0.4286    0.6000    0.5000        50\n",
            "                umbrella     0.3429    0.2400    0.2824        50\n",
            "                vestment     0.5490    0.5600    0.5545        50\n",
            "                 viaduct     0.6923    0.7200    0.7059        50\n",
            "              volleyball     0.6667    0.8000    0.7273        50\n",
            "               water jug     0.3571    0.3000    0.3261        50\n",
            "             water tower     0.7885    0.8200    0.8039        50\n",
            "                     wok     0.6000    0.6600    0.6286        50\n",
            "            wooden spoon     0.2982    0.3400    0.3178        50\n",
            "              comic book     0.8889    0.8000    0.8421        50\n",
            "                   plate     0.4727    0.5200    0.4952        50\n",
            "               guacamole     0.8636    0.7600    0.8085        50\n",
            "               ice cream     0.4035    0.4600    0.4299        50\n",
            "               ice lolly     0.4400    0.4400    0.4400        50\n",
            "                 pretzel     0.8205    0.6400    0.7191        50\n",
            "           mashed potato     0.5217    0.4800    0.5000        50\n",
            "             cauliflower     0.7838    0.5800    0.6667        50\n",
            "             bell pepper     0.7736    0.8200    0.7961        50\n",
            "                mushroom     0.6981    0.7400    0.7184        50\n",
            "                  orange     0.7111    0.6400    0.6737        50\n",
            "                   lemon     0.7143    0.7000    0.7071        50\n",
            "                  banana     0.6066    0.7400    0.6667        50\n",
            "             pomegranate     0.8182    0.9000    0.8571        50\n",
            "               meat loaf     0.5957    0.5600    0.5773        50\n",
            "                   pizza     0.7347    0.7200    0.7273        50\n",
            "                  potpie     0.6481    0.7000    0.6731        50\n",
            "                espresso     0.7333    0.8800    0.8000        50\n",
            "                     alp     0.7872    0.7400    0.7629        50\n",
            "                   cliff     0.5357    0.6000    0.5660        50\n",
            "              coral reef     0.5965    0.6800    0.6355        50\n",
            "                lakeside     0.3556    0.3200    0.3368        50\n",
            "                seashore     0.4189    0.6200    0.5000        50\n",
            "                   acorn     0.6078    0.6200    0.6139        50\n",
            "\n",
            "               micro avg     0.6113    0.6113    0.6113     10000\n",
            "               macro avg     0.6127    0.6113    0.6090     10000\n",
            "            weighted avg     0.6127    0.6113    0.6090     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q2Wg474WW66C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We consider the classes with precision lower than 45% to be weighted reciprocal times to its ratio with 45%. We consider weights of classes with precision above 45% as 1. The reason behind this is our average precison of 60% and most of the classes lies within +-15% of it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "arRqNdsEYoxE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 28 classes that have precision less than 45%\n",
        "\n",
        "27 - Labrador Retriever,\n",
        "29 - Standard Poodle,\n",
        "48 - Hog,\n",
        "62 - Apron,\n",
        "64 - Bannister,\n",
        "77 - Bow-tie,\n",
        "80 - Bucket,\n",
        "94 - Convertible,\n",
        "99 - Drumstick,\n",
        "100 - Dumbbell,\n",
        "106 - GasMask,\n",
        "120 - Miniskirt,\n",
        "131 - Plunger,\n",
        "132 - Pole,\n",
        "135 - Pop Bottle,\n",
        "136 - Potter's Wheel,\n",
        "138 - Punching bag,\n",
        "151 - Space Heater,\n",
        "159 - Syringe,\n",
        "160 - Teapot,\n",
        "167- Turnstile,\n",
        "168 - Umbrella,\n",
        "172 - WaterJug,\n",
        "175 - Wooden Spoon,\n",
        "179 - Ice cream,\n",
        "180 -Ice Lolly,\n",
        "197 - Lakeside,\n",
        "198- seashore"
      ]
    },
    {
      "metadata": {
        "id": "2I8n_thH0uCM",
        "colab_type": "code",
        "outputId": "2033975e-7394-4bec-b760-b1508d279971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# Confusion Matrix of Wooden Spoon class\n",
        "confusion_matrix(validation_generator.classes, predicted_class_indices)[175]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
              "        0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  3,  1,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  1,\n",
              "        1,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  2, 17,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  0,\n",
              "        0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "le5Ye0936UIM",
        "colab_type": "code",
        "outputId": "dcb762db-77bf-4fb0-b742-2e4136927f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# Confusion Matrix of Monarch Class\n",
        "confusion_matrix(validation_generator.classes, predicted_class_indices)[44]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  2,  1,  0,  0,  0,  1, 44,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "C6cSfZFaL-91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class Weight dictionary\n",
        "class_weights = {0:1,1:1,2:1,3:1,4:1,5:1,6:1,7:1,8:1,9:1,10:1,\n",
        "                 11:1,12:1,13:1,14:1,15:1,16:1,17:1,18:1,19:1,20:1,\n",
        "                 21:1,22:1,23:1,24:1,25:1,26:1,27:1.12,28:1,29:1.01,30:1,\n",
        "                 31:1,32:1,33:1,34:1,35:1,36:1,37:1,38:1,39:1,40:1,\n",
        "                 41:1,42:1,43:1,44:1,45:1,46:1,47:1,48:1.06,49:1,50:1,\n",
        "                 51:1,52:1,53:1,54:1,55:1,56:1,57:1,58:1,59:1,60:1,\n",
        "                 61:1,62:1.15,63:1,64:1.19,65:1,66:1,67:1,68:1,69:1,70:1,\n",
        "                 71:1,72:1,73:1,74:1,75:1,76:1,77:1.10,78:1,79:1,80:1.27,\n",
        "                 81:1,82:1,83:1,84:1,85:1,86:1,87:1,88:1,89:1,90:1,\n",
        "                 91:1,92:1,93:1,94:1,95:1,96:1,97:1,98:1,99:1.37,100:1.18,\n",
        "                 101:1,102:1,103:1,104:1,105:1,106:1.02,107:1,108:1,109:1,110:1,\n",
        "                 111:1,112:1,113:1,114:1,115:1,116:1,117:1,118:1,119:1,120:1.06,\n",
        "                 121:1,122:1,123:1,124:1,125:1,126:1,127:1,128:1,129:1,130:1,\n",
        "                 131:1.49,132:1.52,133:1,134:1,135:1.31,136:1.06,137:1,138:1.33,139:1,140:1,\n",
        "                 141:1,142:1,143:1,144:1,145:1,146:1,147:1,148:1,149:1,150:1,\n",
        "                 151:1.21,152:1,153:1,154:1,155:1,156:1,157:1,158:1,159:1.43,160:1.21,\n",
        "                 161:1,162:1,163:1,164:1,165:1,166:1,167:1.05,168:1.31,169:1,170:1,\n",
        "                 171:1,172:1.26,173:1,174:1,175:1.51,176:1,177:1,178:1,179:1.16,180:1.02,\n",
        "                 181:1,182:1,183:1,184:1,185:1,186:1,187:1,188:1,189:1,190:1,\n",
        "                 191:1,192:1,193:1,194:1,195:1,196:1,197:1.26,198:1.07,199:1,\n",
        "                }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxsmBA9ZprQh",
        "colab_type": "code",
        "outputId": "297064f9-dc6b-4c63-a6c8-06c7a7353ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "checkpointer_weighted = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/weighted_model.hdf5\", verbose=1, save_best_only=True, monitor=\"val_acc\")\n",
        "extended_model.fit_generator(train_generator,\n",
        "                             epochs=10,\n",
        "                             steps_per_epoch= np.ceil(num_train/batch_size),\n",
        "                             validation_steps= np.ceil(num_validation/batch_size),\n",
        "                             validation_data=validation_generator,\n",
        "                             verbose=1, callbacks=[lr_reducer, checkpointer_weighted],\n",
        "                             class_weight= class_weights,\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 1210s 2s/step - loss: 1.4202 - acc: 0.7610 - val_loss: 2.1348 - val_acc: 0.6107\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.61070, saving model to /content/drive/My Drive/Colab Notebooks/weighted_model.hdf5\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 1191s 2s/step - loss: 1.4117 - acc: 0.7616 - val_loss: 2.1412 - val_acc: 0.6084\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61070\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 1192s 2s/step - loss: 1.3996 - acc: 0.7656 - val_loss: 2.1261 - val_acc: 0.6121\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.61070 to 0.61210, saving model to /content/drive/My Drive/Colab Notebooks/weighted_model.hdf5\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 1191s 2s/step - loss: 1.3864 - acc: 0.7701 - val_loss: 2.1379 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61210\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 1192s 2s/step - loss: 1.3818 - acc: 0.7703 - val_loss: 2.1296 - val_acc: 0.6131\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.61210 to 0.61310, saving model to /content/drive/My Drive/Colab Notebooks/weighted_model.hdf5\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 1191s 2s/step - loss: 1.3758 - acc: 0.7711 - val_loss: 2.1320 - val_acc: 0.6120\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61310\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 1192s 2s/step - loss: 1.3723 - acc: 0.7714 - val_loss: 2.1304 - val_acc: 0.6136\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.61310 to 0.61360, saving model to /content/drive/My Drive/Colab Notebooks/weighted_model.hdf5\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 1192s 2s/step - loss: 1.3628 - acc: 0.7757 - val_loss: 2.1300 - val_acc: 0.6133\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61360\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 1191s 2s/step - loss: 1.3499 - acc: 0.7770 - val_loss: 2.1173 - val_acc: 0.6158\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.61360 to 0.61580, saving model to /content/drive/My Drive/Colab Notebooks/weighted_model.hdf5\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 1191s 2s/step - loss: 1.3418 - acc: 0.7817 - val_loss: 2.1263 - val_acc: 0.6123\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.61580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbca6d41080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "ba9ESM57Syqe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### I tried every kind of hyperparameters I could and this is the best I could manage. I ran for more than 50 epochs for class_weights approach but after few initial jumps in val acc it stagnates. So finalized with 10 epochs."
      ]
    },
    {
      "metadata": {
        "id": "D_9lRdm_E1sI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Top Validation Accuracy : 61.58%"
      ]
    },
    {
      "metadata": {
        "id": "EYIRyD8Wq9tU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}